"""
T-LAFS æ¡†æ¶é›†æˆ MVSE æ¢é’ˆæ¨¡å—
åœ¨åŸæœ‰çš„ clp_probe_experiment.py åŸºç¡€ä¸Šæ·»åŠ  MVSE æ¢é’ˆåŠŸèƒ½
"""

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
import warnings
import os
import sys
from typing import List, Dict, Any

# å¯¼å…¥ MVSE æ¨¡å—
from mvse_embedding import MVSEEmbedding
from mvse_probe_integration import MVSEProbeForecaster, create_mvse_probe_features, train_mvse_probe_model

# åœ¨åŸæœ‰çš„ tlafs_core.py åŸºç¡€ä¸Šæ·»åŠ  MVSE æ¢é’ˆåŠŸèƒ½
from tlafs_core import TLAFS_Algorithm as OriginalTLAFS
from tlafs_core import gemini_model

warnings.filterwarnings('ignore')


def generate_mvse_features_for_tlafs(df, target_col='temp', hist_len=90, num_lags=14):
    """
    ä¸º T-LAFS æ¡†æ¶ç”Ÿæˆ MVSE æ¢é’ˆç‰¹å¾
    
    è¿™ä¸ªå‡½æ•°ä¸“é—¨ä¸º T-LAFS çš„ execute_plan æ–¹æ³•è®¾è®¡
    """
    print("  - ğŸ”® ç”Ÿæˆ MVSE æ¢é’ˆç‰¹å¾...")
    
    try:
        # åˆ›å»ºç‰¹å¾
        hist_sequences, lag_features, targets, valid_indices, target_scaler = create_mvse_probe_features(
            df, target_col=target_col, hist_len=hist_len, num_lags=num_lags
        )
        
        if len(hist_sequences) == 0:
            print("  - âš ï¸ æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆ MVSE ç‰¹å¾")
            return df
        
        # è®­ç»ƒæ¨¡å‹ï¼ˆä½¿ç”¨è¾ƒå°‘çš„è½®æ¬¡ä»¥æé«˜é€Ÿåº¦ï¼‰
        model, best_loss = train_mvse_probe_model(
            hist_sequences, lag_features, targets,
            epochs=30, mask_rate=0.3, batch_size=64
        )
        
        # ç”Ÿæˆç‰¹å¾
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model.eval()
        
        with torch.no_grad():
            # è·å– MVSE ç¼–ç ç‰¹å¾
            hist_tensor = torch.FloatTensor(hist_sequences).to(device)
            mvse_features = model.mvse_encoder(hist_tensor).cpu().numpy()
            
            # è·å–æ± åŒ–ç‰¹å¾ç”¨äºåˆ†æ
            pooling_features = model.mvse_encoder.get_pooling_features(hist_tensor)
            gap_features = pooling_features['gap'].cpu().numpy()
            gmp_features = pooling_features['gmp'].cpu().numpy()
        
        # åˆ›å»ºç‰¹å¾ DataFrame
        feature_names = []
        all_features = []
        
        # 1. MVSE ä¸»è¦ç‰¹å¾ï¼ˆé™ç»´åˆ°16ç»´ä»¥å‡å°‘ç‰¹å¾æ•°é‡ï¼‰
        mvse_cols = [f"mvse_feat_{i}" for i in range(min(16, mvse_features.shape[1]))]
        feature_names.extend(mvse_cols)
        all_features.append(mvse_features[:, :len(mvse_cols)])
        
        # 2. æ± åŒ–ç‰¹å¾çš„ç»Ÿè®¡æ‘˜è¦
        gap_stats = np.column_stack([
            gap_features.mean(axis=1),
            gap_features.std(axis=1),
            gap_features.max(axis=1),
            gap_features.min(axis=1)
        ])
        gap_stat_cols = ['mvse_gap_mean', 'mvse_gap_std', 'mvse_gap_max', 'mvse_gap_min']
        feature_names.extend(gap_stat_cols)
        all_features.append(gap_stats)
        
        gmp_stats = np.column_stack([
            gmp_features.mean(axis=1),
            gmp_features.std(axis=1),
            gmp_features.max(axis=1),
            gmp_features.min(axis=1)
        ])
        gmp_stat_cols = ['mvse_gmp_mean', 'mvse_gmp_std', 'mvse_gmp_max', 'mvse_gmp_min']
        feature_names.extend(gmp_stat_cols)
        all_features.append(gmp_stats)
        
        # åˆå¹¶æ‰€æœ‰ç‰¹å¾
        final_features = np.concatenate(all_features, axis=1)
        
        # åˆ›å»º DataFrame
        features_df = pd.DataFrame(
            final_features,
            index=valid_indices,
            columns=feature_names
        )
        
        print(f"  - âœ… MVSE ç‰¹å¾ç”Ÿæˆå®Œæˆ: {len(feature_names)} ä¸ªç‰¹å¾, è®­ç»ƒæŸå¤±: {best_loss:.6f}")
        
        # ä½¿ç”¨ shift(1) é¿å…æ•°æ®æ³„éœ²
        return df.join(features_df.shift(1))
        
    except Exception as e:
        print(f"  - âŒ MVSE ç‰¹å¾ç”Ÿæˆå¤±è´¥: {e}")
        return df


def add_mvse_to_execute_plan():
    """
    ä¸º TLAFS çš„ execute_plan æ–¹æ³•æ·»åŠ  MVSE ç‰¹å¾ç”ŸæˆåŠŸèƒ½
    """
    def execute_plan_with_mvse(df: pd.DataFrame, plan: List[Dict[str, Any]]):
        """
        æ‰§è¡Œç‰¹å¾å·¥ç¨‹è®¡åˆ’ï¼ŒåŒ…æ‹¬ MVSE ç‰¹å¾ç”Ÿæˆ
        
        Args:
            df (pd.DataFrame): è¾“å…¥æ•°æ®
            plan (List[Dict]): ç‰¹å¾å·¥ç¨‹è®¡åˆ’
            
        Returns:
            pd.DataFrame: å¤„ç†åçš„æ•°æ®æ¡†
        """
        from tlafs_utils import generate_mvse_features_for_tlafs
        
        # æ‰§è¡ŒåŸå§‹è®¡åˆ’
        for operation in plan:
            if operation['operation'] == 'create_mvse_features':
                df = generate_mvse_features_for_tlafs(
                    df,
                    target_col=operation.get('target_col', 'temp'),
                    hist_len=operation.get('hist_len', 90),
                    num_lags=operation.get('num_lags', 14)
                )
            else:
                # å¤„ç†å…¶ä»–æ“ä½œ...
                pass
                
        return df
    
    return execute_plan_with_mvse


def add_mvse_to_llm_prompt():
    """
    ä¸º TLAFS çš„ LLM æç¤ºè¯æ·»åŠ  MVSE ç›¸å…³è¯´æ˜
    """
    def get_enhanced_prompt(context_prompt: str) -> str:
        """
        å¢å¼º LLM æç¤ºè¯ï¼Œæ·»åŠ  MVSE ç›¸å…³è¯´æ˜
        
        Args:
            context_prompt (str): åŸå§‹æç¤ºè¯
            
        Returns:
            str: å¢å¼ºåçš„æç¤ºè¯
        """
        mvse_context = """
        å¯ç”¨çš„ MVSE ç‰¹å¾å·¥ç¨‹æ“ä½œï¼š
        1. create_mvse_features: ç”Ÿæˆå¤šè§†è§’åºåˆ—ç¼–ç ç‰¹å¾
           - target_col: ç›®æ ‡åˆ—å
           - hist_len: å†å²åºåˆ—é•¿åº¦
           - num_lags: æ»åç‰¹å¾æ•°é‡
        """
        
        return context_prompt + mvse_context
    
    return get_enhanced_prompt


def create_enhanced_tlafs_with_mvse():
    """
    åˆ›å»ºå¢å¼ºç‰ˆçš„ TLAFS ç±»ï¼Œé›†æˆ MVSE åŠŸèƒ½
    """
    from tlafs_core import TLAFS_Algorithm
    
    class EnhancedTLAFS(TLAFS_Algorithm):
        def __init__(self, *args, **kwargs):
            super().__init__(*args, **kwargs)
            self.execute_plan = add_mvse_to_execute_plan()
            self.get_plan_from_llm = add_mvse_to_llm_prompt()
    
    return EnhancedTLAFS


def test_mvse_integration_in_tlafs():
    """
    æµ‹è¯• MVSE åœ¨ TLAFS ä¸­çš„é›†æˆ
    """
    print("ğŸ§ª æµ‹è¯• MVSE åœ¨ TLAFS ä¸­çš„é›†æˆ...")
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    dates = pd.date_range('2020-01-01', periods=1000, freq='D')
    np.random.seed(42)
    
    # ç”Ÿæˆå¸¦æœ‰å­£èŠ‚æ€§å’Œè¶‹åŠ¿çš„æ—¶é—´åºåˆ—
    t = np.arange(len(dates))
    seasonal = 10 * np.sin(2 * np.pi * t / 365.25)  # å¹´åº¦å­£èŠ‚æ€§
    trend = 0.01 * t  # çº¿æ€§è¶‹åŠ¿
    noise = np.random.normal(0, 2, len(dates))
    temp = 20 + seasonal + trend + noise
    
    df = pd.DataFrame({
        'date': dates,
        'temp': temp
    })
    
    # åˆ›å»ºå¢å¼ºç‰ˆ TLAFS
    EnhancedTLAFS = create_enhanced_tlafs_with_mvse()
    
    # æµ‹è¯• MVSE ç‰¹å¾ç”Ÿæˆ
    plan = [{
        'operation': 'create_mvse_features',
        'target_col': 'temp',
        'hist_len': 90,
        'num_lags': 14
    }]
    
    df_with_mvse = EnhancedTLAFS.execute_plan(df.copy(), plan)
    
    # æ£€æŸ¥ç»“æœ
    mvse_cols = [col for col in df_with_mvse.columns if 'mvse_' in col]
    print(f"âœ… MVSE ç‰¹å¾ç”Ÿæˆæµ‹è¯•:")
    print(f"   - ç”Ÿæˆçš„ç‰¹å¾æ•°é‡: {len(mvse_cols)}")
    print(f"   - å‰5ä¸ªç‰¹å¾: {mvse_cols[:5]}")
    
    print("\nâœ… MVSE é›†æˆæµ‹è¯•å®Œæˆï¼")


def create_integration_guide():
    """
    åˆ›å»ºé›†æˆæŒ‡å—
    """
    guide = """
# ğŸ”§ MVSE æ¢é’ˆé›†æˆåˆ° T-LAFS çš„å®Œæ•´æŒ‡å—

## æ–¹æ³• 1: ç›´æ¥ä¿®æ”¹ç°æœ‰æ–‡ä»¶ (æ¨è)

### æ­¥éª¤ 1: æ·»åŠ å¯¼å…¥
åœ¨ `clp_probe_experiment.py` æ–‡ä»¶é¡¶éƒ¨æ·»åŠ ï¼š
```python
from mvse_embedding import MVSEEmbedding
from mvse_probe_integration import generate_mvse_probe_features_for_tlafs
```

### æ­¥éª¤ 2: ä¿®æ”¹ execute_plan æ–¹æ³•
åœ¨ `execute_plan` æ–¹æ³•çš„ `elif op == "create_probe_features":` åé¢æ·»åŠ ï¼š
```python
elif op == "create_mvse_features":
    print("  - Generating MVSE probe features...")
    temp_df = generate_mvse_features_for_tlafs(temp_df, target_col)
    print("  - âœ… MVSE features generated.")
```

### æ­¥éª¤ 3: ä¿®æ”¹ LLM æç¤º
åœ¨ `advanced_tools` å­—ç¬¦ä¸²ä¸­æ·»åŠ ï¼š
```python
# 4. MVSE Probe Features (NEWEST & HIGHLY EFFICIENT) â­ RECOMMENDED â­
# Multi-View Sequential Embedding: Uses 3 pooling strategies to extract robust features.
# Generates only 24 high-quality features (much fewer than traditional probe_features).
- {{"operation": "create_mvse_features"}}
```

## æ–¹æ³• 2: ä½¿ç”¨å¢å¼ºç‰ˆç±» (å®‰å…¨)

### ä½¿ç”¨ EnhancedTLAFS ç±»ï¼š
```python
from mvse_tlafs_integration import create_enhanced_tlafs_with_mvse

# åˆ›å»ºå¢å¼ºç‰ˆ T-LAFS
EnhancedTLAFS = create_enhanced_tlafs_with_mvse()

# åœ¨ main() å‡½æ•°ä¸­æ›¿æ¢åŸæ¥çš„ TLAFS_Algorithm
tlafs = EnhancedTLAFS(
    base_df=base_df,
    target_col=TARGET_COL,
    n_iterations=N_ITERATIONS,
    results_dir=results_dir
)
```

## ä¼˜åŠ¿å¯¹æ¯”

### MVSE vs ä¼ ç»Ÿ Probe Features:
- **ç‰¹å¾æ•°é‡**: 24 vs 70+ 
- **è®­ç»ƒé€Ÿåº¦**: æ›´å¿« (30 epochs vs 150 epochs)
- **è¿‡æ‹Ÿåˆé£é™©**: æ›´ä½ (æ›´å°‘ç»´åº¦)
- **é²æ£’æ€§**: æ›´å¼º (éšæœºé®ç½©æœºåˆ¶)
- **æ³›åŒ–èƒ½åŠ›**: æ›´å¥½ (å¤šè§†è§’æ± åŒ–)

## ä½¿ç”¨å»ºè®®

1. **ä¼˜å…ˆä½¿ç”¨ MVSE**: åœ¨é«˜çº§é˜¶æ®µä¼˜å…ˆæ¨è `create_mvse_features`
2. **ç»„åˆä½¿ç”¨**: å¯ä»¥ä¸ä¼ ç»Ÿç‰¹å¾å·¥ç¨‹æ–¹æ³•ç»„åˆ
3. **å‚æ•°è°ƒä¼˜**: å¯ä»¥è°ƒæ•´ `hist_len`, `num_lags`, `mask_rate` ç­‰å‚æ•°
4. **ç›‘æ§æ€§èƒ½**: è§‚å¯Ÿ MVSE ç‰¹å¾åœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„è¡¨ç°
"""
    
    return guide


if __name__ == "__main__":
    # è¿è¡Œé›†æˆæµ‹è¯•
    test_mvse_integration_in_tlafs()
    
    # æ‰“å°é›†æˆæŒ‡å—
    print("\n" + "="*80)
    print(create_integration_guide()) 