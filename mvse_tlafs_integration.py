"""
T-LAFS æ¡†æ¶é›†æˆ MVSE æ¢é’ˆæ¨¡å—
åœ¨åŸæœ‰çš„ clp_probe_experiment.py åŸºç¡€ä¸Šæ·»åŠ  MVSE æ¢é’ˆåŠŸèƒ½
"""

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
import warnings
import os
import sys

# å¯¼å…¥ MVSE æ¨¡å—
from mvse_embedding import MVSEEmbedding
from mvse_probe_integration import MVSEProbeForecaster, create_mvse_probe_features, train_mvse_probe_model

warnings.filterwarnings('ignore')


def generate_mvse_features_for_tlafs(df, target_col, model, target_scaler, hist_len=90, num_lags=14):
    """
    ä¸º T-LAFS æ¡†æ¶ç”Ÿæˆ MVSE æ¢é’ˆç‰¹å¾ï¼ˆä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼‰
    
    è¿™ä¸ªå‡½æ•°ä¸“é—¨ä¸º T-LAFS çš„ execute_plan æ–¹æ³•è®¾è®¡
    """
    print("  - ğŸ”® ä½¿ç”¨é¢„è®­ç»ƒçš„ MVSE æ¨¡å‹ç”Ÿæˆæ¢é’ˆç‰¹å¾...")
    
    try:
        # åˆ›å»ºç”¨äºæ¨ç†çš„è¾“å…¥æ•°æ®
        hist_sequences, lag_features, _, valid_indices, _ = create_mvse_probe_features(
            df, target_col=target_col, hist_len=hist_len, num_lags=num_lags, scaler=target_scaler
        )
        
        if len(hist_sequences) == 0:
            print("  - âš ï¸ æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆ MVSE ç‰¹å¾")
            return df
        
        # ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆç‰¹å¾
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model.eval()
        model.to(device)
        
        with torch.no_grad():
            # è·å– MVSE ç¼–ç ç‰¹å¾
            hist_tensor = torch.FloatTensor(hist_sequences).to(device)
            mvse_features = model.mvse_encoder(hist_tensor).cpu().numpy()
            
            # è·å–æ± åŒ–ç‰¹å¾ç”¨äºåˆ†æ
            pooling_features = model.mvse_encoder.get_pooling_features(hist_tensor)
            gap_features = pooling_features['gap'].cpu().numpy()
            gmp_features = pooling_features['gmp'].cpu().numpy()
        
        # åˆ›å»ºç‰¹å¾ DataFrame
        feature_names = []
        all_features = []
        
        # 1. MVSE ä¸»è¦ç‰¹å¾ï¼ˆé™ç»´åˆ°16ç»´ä»¥å‡å°‘ç‰¹å¾æ•°é‡ï¼‰
        mvse_cols = [f"mvse_feat_{i}" for i in range(min(16, mvse_features.shape[1]))]
        feature_names.extend(mvse_cols)
        all_features.append(mvse_features[:, :len(mvse_cols)])
        
        # 2. æ± åŒ–ç‰¹å¾çš„ç»Ÿè®¡æ‘˜è¦
        gap_stats = np.column_stack([
            gap_features.mean(axis=1),
            gap_features.std(axis=1),
            gap_features.max(axis=1),
            gap_features.min(axis=1)
        ])
        gap_stat_cols = ['mvse_gap_mean', 'mvse_gap_std', 'mvse_gap_max', 'mvse_gap_min']
        feature_names.extend(gap_stat_cols)
        all_features.append(gap_stats)
        
        gmp_stats = np.column_stack([
            gmp_features.mean(axis=1),
            gmp_features.std(axis=1),
            gmp_features.max(axis=1),
            gmp_features.min(axis=1)
        ])
        gmp_stat_cols = ['mvse_gmp_mean', 'mvse_gmp_std', 'mvse_gmp_max', 'mvse_gmp_min']
        feature_names.extend(gmp_stat_cols)
        all_features.append(gmp_stats)
        
        # åˆå¹¶æ‰€æœ‰ç‰¹å¾
        final_features = np.concatenate(all_features, axis=1)
        
        # åˆ›å»º DataFrame
        features_df = pd.DataFrame(
            final_features,
            index=valid_indices,
            columns=feature_names
        )
        
        print(f"  - âœ… MVSE ç‰¹å¾ç”Ÿæˆå®Œæˆ: {len(feature_names)} ä¸ªç‰¹å¾")
        
        # ä½¿ç”¨ shift(1) é¿å…æ•°æ®æ³„éœ²
        return df.join(features_df.shift(1))
        
    except Exception as e:
        import traceback
        print(f"  - âŒ MVSE ç‰¹å¾ç”Ÿæˆå¤±è´¥: {e}\n{traceback.format_exc()}")
        return df


def add_mvse_to_execute_plan():
    """
    è¿”å›ä¸€ä¸ªåŒ…å« MVSE æ“ä½œçš„ä»£ç ç‰‡æ®µï¼Œå¯ä»¥æ·»åŠ åˆ° execute_plan æ–¹æ³•ä¸­
    """
    mvse_operation_code = '''
                elif op == "create_mvse_features":
                    print("  - Generating MVSE probe features...")
                    temp_df = generate_mvse_features_for_tlafs(temp_df, target_col, model, target_scaler)
                    print("  - âœ… MVSE features generated.")
    '''
    return mvse_operation_code


def add_mvse_to_llm_prompt():
    """
    è¿”å›è¦æ·»åŠ åˆ° LLM æç¤ºä¸­çš„ MVSE å·¥å…·æè¿°
    """
    mvse_tool_description = '''
# 4. MVSE Probe Features (NEWEST & HIGHLY EFFICIENT)
# Multi-View Sequential Embedding: Uses 3 pooling strategies (GAP, GMP, MaskedGAP) to extract robust features.
# Generates only 24 high-quality features (much fewer than traditional probe_features).
# Excellent for capturing both trends and anomalies with strong robustness.
- {"operation": "create_mvse_features"}
'''
    return mvse_tool_description


def create_enhanced_tlafs_with_mvse():
    """
    åˆ›å»ºä¸€ä¸ªå¢å¼ºç‰ˆçš„ T-LAFS ç±»ï¼Œé›†æˆäº† MVSE æ¢é’ˆåŠŸèƒ½
    """
    
    # è¿™é‡Œæˆ‘ä»¬éœ€è¦ä»åŸå§‹æ–‡ä»¶å¯¼å…¥ TLAFS_Algorithm ç±»
    # ç”±äºç›´æ¥ä¿®æ”¹åŸæ–‡ä»¶å¯èƒ½å½±å“ç°æœ‰åŠŸèƒ½ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç»§æ‰¿ç±»
    
    try:
        # å°è¯•å¯¼å…¥åŸå§‹çš„ TLAFS_Algorithm
        from clp_probe_experiment import TLAFS_Algorithm as OriginalTLAFS
        
        class EnhancedTLAFS(OriginalTLAFS):
            """
            å¢å¼ºç‰ˆ T-LAFSï¼Œé›†æˆäº† MVSE æ¢é’ˆåŠŸèƒ½
            """
            
            @staticmethod
            def execute_plan(df: pd.DataFrame, plan: list):
                """
                é‡å†™ execute_plan æ–¹æ³•ï¼Œæ·»åŠ  MVSE æ”¯æŒ
                """
                # é¦–å…ˆè°ƒç”¨åŸå§‹çš„ execute_plan å¤„ç†å…¶ä»–æ“ä½œ
                temp_df = df.copy()
                target_col = EnhancedTLAFS.target_col_static
                
                # ç¡®ä¿åŸºç¡€æ—¶é—´ç‰¹å¾å­˜åœ¨
                required_time_cols = ['dayofweek', 'month', 'weekofyear', 'is_weekend']
                if not all(col in temp_df.columns for col in required_time_cols):
                    if 'dayofweek' not in temp_df.columns:
                        temp_df['dayofweek'] = temp_df['date'].dt.dayofweek
                    if 'month' not in temp_df.columns:
                        temp_df['month'] = temp_df['date'].dt.month
                    if 'weekofyear' not in temp_df.columns:
                        temp_df['weekofyear'] = temp_df['date'].dt.isocalendar().week.astype(int)
                    if 'is_weekend' not in temp_df.columns:
                        temp_df['is_weekend'] = (temp_df['date'].dt.dayofweek >= 5).astype(int)
                
                for step in plan:
                    op = step.get("operation")
                    
                    try:
                        if op == "create_mvse_features":
                            print("  - Generating MVSE probe features...")
                            temp_df = generate_mvse_features_for_tlafs(temp_df, target_col, model, target_scaler)
                            print("  - âœ… MVSE features generated.")
                        else:
                            # å¯¹äºå…¶ä»–æ“ä½œï¼Œè°ƒç”¨çˆ¶ç±»çš„æ–¹æ³•
                            # ç”±äºçˆ¶ç±»æ–¹æ³•æ˜¯é™æ€çš„ï¼Œæˆ‘ä»¬éœ€è¦é‡æ–°å®ç°æ ¸å¿ƒé€»è¾‘
                            temp_df = OriginalTLAFS.execute_plan(temp_df, [step])
                            
                    except Exception as e:
                        import traceback
                        print(f"  - âŒ ERROR executing step {step}. Error: {e}\n{traceback.format_exc()}")
                
                return temp_df
            
            def get_plan_from_llm(self, context_prompt, iteration_num, max_iterations):
                """
                é‡å†™ LLM æç¤ºç”Ÿæˆæ–¹æ³•ï¼Œæ·»åŠ  MVSE å·¥å…·
                """
                # è°ƒç”¨çˆ¶ç±»æ–¹æ³•è·å–åŸºç¡€æç¤º
                original_prompt = super().get_plan_from_llm.__func__(self, context_prompt, iteration_num, max_iterations)
                
                # å¦‚æœæ˜¯é«˜çº§é˜¶æ®µï¼Œæˆ‘ä»¬éœ€è¦ä¿®æ”¹æç¤ºä»¥åŒ…å« MVSE
                stage = "advanced"
                if (iteration_num / max_iterations) < 0.4:
                    stage = "basic"
                
                if stage == "advanced":
                    # é‡æ–°ç”ŸæˆåŒ…å« MVSE çš„æç¤º
                    return self._get_enhanced_plan_from_llm(context_prompt, iteration_num, max_iterations)
                else:
                    return original_prompt
            
            def _get_enhanced_plan_from_llm(self, context_prompt, iteration_num, max_iterations):
                """
                ç”ŸæˆåŒ…å« MVSE çš„å¢å¼ºæç¤º
                """
                from clp_probe_experiment import gemini_model
                import json
                
                base_prompt = f"""You are a Data Scientist RL agent. Your goal is to create a feature engineering plan to maximize the Fusion R^2 score.
Your response MUST be a valid JSON list of operations: `[ {{"operation": "op_name", ...}}, ... ]`.
The target column is '{self.target_col}'.
"""
                
                basic_tools = """
# *** STAGE 1: BASIC FEATURE ENGINEERING ***
# Focus on creating a strong baseline with fundamental time-series features.
# AVAILABLE TOOLS:
- {{"operation": "create_lag", "on": "feature_name", "days": int, "id": "..."}}
- {{"operation": "create_diff", "on": "feature_name", "periods": int, "id": "..."}}
- {{"operation": "create_rolling_mean", "on": "feature_name", "window": int, "id": "..."}}
- {{"operation": "create_rolling_std", "on": "feature_name", "window": int, "id": "..."}}
- {{"operation": "create_ewm", "on": "feature_name", "span": int, "id": "..."}}
- {{"operation": "create_fourier_features", "period": 365.25, "order": 4}}
- {{"operation": "create_interaction", "features": ["feat1", "feat2"], "id": "..."}}
- {{"operation": "delete_feature", "feature": "feature_name"}}
"""

                advanced_tools = """
# *** STAGE 2: ADVANCED FEATURE ENGINEERING ***
# Now you can use powerful learned embeddings and meta-forecasts. Combine them with the best basic features.
# AVAILABLE TOOLS (includes all basic tools plus):
# 1. Learned Embeddings (VERY POWERFUL)
- {{"operation": "create_learned_embedding", "window": [90, 365, 730], "id": "UNIQUE_ID"}}

# 2. Meta-Forecast Features
- {{"operation": "create_forecast_feature", "model_name": ["SimpleNN_meta", "EnhancedNN_meta"], "id": "UNIQUE_ID"}}

# 3. Traditional Attention Probe Features (POWERFUL but HIGH-DIMENSIONAL)
# This generates 70+ features from a 365-day lookback window using an attention-based probe.
- {{"operation": "create_probe_features"}}

# 4. MVSE Probe Features (NEWEST & HIGHLY EFFICIENT) â­ RECOMMENDED â­
# Multi-View Sequential Embedding: Uses 3 pooling strategies (GAP, GMP, MaskedGAP) to extract robust features.
# Generates only 24 high-quality features (much fewer than traditional probe_features).
# Excellent for capturing both trends and anomalies with strong robustness.
# ADVANTAGE: Lower dimensionality, better generalization, faster training.
- {{"operation": "create_mvse_features"}}
"""
                
                rules = """
*** RULES ***
- IDs must be unique. Do not reuse IDs from "Available Features".
- Propose short plans (1-3 steps).
- For parameters shown with a list of options (e.g., "window": [90, 365]), you MUST CHOOSE ONLY ONE value.
- `create_mvse_features` is HIGHLY RECOMMENDED over `create_probe_features` due to better efficiency and lower overfitting risk.
- `create_learned_embedding` is very powerful. Try interacting it with other features using `create_interaction`.
- Prefer `create_mvse_features` when you need advanced probe capabilities with better generalization.
"""

                system_prompt = base_prompt + basic_tools + advanced_tools + rules
                
                try:
                    if gemini_model is None:
                        raise Exception("Gemini model not initialized.")
                    
                    full_prompt_for_gemini = system_prompt + "\n\n" + context_prompt
                    response = gemini_model.generate_content(full_prompt_for_gemini)
                    plan_str = response.text
                    parsed_json = json.loads(plan_str)

                    if isinstance(parsed_json, dict) and "plan" in parsed_json:
                        plan = parsed_json.get("plan", [])
                        return plan if isinstance(plan, list) else [plan]
                    elif isinstance(parsed_json, list):
                        return parsed_json
                    elif isinstance(parsed_json, dict) and "operation" in parsed_json:
                        return [parsed_json]
                    else:
                        print(f"  - âš ï¸ Warning: LLM returned unexpected structure: {parsed_json}")
                        return []
                        
                except Exception as e:
                    print(f"âŒ Error calling Gemini: {e}")
                    return [{"operation": "create_mvse_features"}]  # é»˜è®¤ä½¿ç”¨ MVSE
        
        return EnhancedTLAFS
        
    except ImportError as e:
        print(f"âŒ æ— æ³•å¯¼å…¥åŸå§‹ TLAFS_Algorithm: {e}")
        print("è¯·ç¡®ä¿ clp_probe_experiment.py æ–‡ä»¶å­˜åœ¨ä¸”å¯å¯¼å…¥")
        return None


def test_mvse_integration_in_tlafs():
    """
    æµ‹è¯• MVSE åœ¨ T-LAFS ä¸­çš„é›†æˆ
    """
    print("ğŸ§ª æµ‹è¯• MVSE åœ¨ T-LAFS ä¸­çš„é›†æˆ...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    dates = pd.date_range('2020-01-01', periods=500, freq='D')
    np.random.seed(42)
    
    # ç”Ÿæˆå¸¦æœ‰å­£èŠ‚æ€§çš„æ—¶é—´åºåˆ—
    t = np.arange(len(dates))
    seasonal = 10 * np.sin(2 * np.pi * t / 365.25)
    trend = 0.01 * t
    noise = np.random.normal(0, 2, len(dates))
    temp = 20 + seasonal + trend + noise
    
    df = pd.DataFrame({
        'date': dates,
        'temp': temp
    })
    
    print(f"ğŸ“Š æµ‹è¯•æ•°æ®: {len(df)} ä¸ªæ ·æœ¬")
    
    # æµ‹è¯• MVSE ç‰¹å¾ç”Ÿæˆ
    print("\nğŸ”§ æµ‹è¯• MVSE ç‰¹å¾ç”Ÿæˆ...")
    df_with_mvse = generate_mvse_features_for_tlafs(df, target_col='temp', model=None, target_scaler=None)
    
    # æ£€æŸ¥ç»“æœ
    mvse_cols = [col for col in df_with_mvse.columns if 'mvse_' in col]
    print(f"âœ… ç”Ÿæˆçš„ MVSE ç‰¹å¾: {len(mvse_cols)} ä¸ª")
    print(f"   ç‰¹å¾åˆ—è¡¨: {mvse_cols}")
    
    # æµ‹è¯•å¢å¼ºç‰ˆ T-LAFS ç±»
    print("\nğŸš€ æµ‹è¯•å¢å¼ºç‰ˆ T-LAFS ç±»...")
    EnhancedTLAFS = create_enhanced_tlafs_with_mvse()
    
    if EnhancedTLAFS:
        print("âœ… å¢å¼ºç‰ˆ T-LAFS ç±»åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯• execute_plan æ–¹æ³•
        test_plan = [{"operation": "create_mvse_features"}]
        
        # æ¨¡æ‹Ÿè®¾ç½®å¿…è¦çš„ç±»å±æ€§
        EnhancedTLAFS.target_col_static = 'temp'
        
        result_df = EnhancedTLAFS.execute_plan(df, test_plan)
        
        new_mvse_cols = [col for col in result_df.columns if 'mvse_' in col]
        print(f"âœ… execute_plan æµ‹è¯•æˆåŠŸ: ç”Ÿæˆäº† {len(new_mvse_cols)} ä¸ª MVSE ç‰¹å¾")
    else:
        print("âŒ å¢å¼ºç‰ˆ T-LAFS ç±»åˆ›å»ºå¤±è´¥")
    
    print("\nâœ… MVSE é›†æˆæµ‹è¯•å®Œæˆï¼")


def create_integration_guide():
    """
    åˆ›å»ºé›†æˆæŒ‡å—
    """
    guide = """
# ğŸ”§ MVSE æ¢é’ˆé›†æˆåˆ° T-LAFS çš„å®Œæ•´æŒ‡å—

## æ–¹æ³• 1: ç›´æ¥ä¿®æ”¹ç°æœ‰æ–‡ä»¶ (æ¨è)

### æ­¥éª¤ 1: æ·»åŠ å¯¼å…¥
åœ¨ `clp_probe_experiment.py` æ–‡ä»¶é¡¶éƒ¨æ·»åŠ ï¼š
```python
from mvse_embedding import MVSEEmbedding
from mvse_probe_integration import generate_mvse_probe_features_for_tlafs
```

### æ­¥éª¤ 2: ä¿®æ”¹ execute_plan æ–¹æ³•
åœ¨ `execute_plan` æ–¹æ³•çš„ `elif op == "create_probe_features":` åé¢æ·»åŠ ï¼š
```python
elif op == "create_mvse_features":
    print("  - Generating MVSE probe features...")
    temp_df = generate_mvse_features_for_tlafs(temp_df, target_col, model, target_scaler)
    print("  - âœ… MVSE features generated.")
```

### æ­¥éª¤ 3: ä¿®æ”¹ LLM æç¤º
åœ¨ `advanced_tools` å­—ç¬¦ä¸²ä¸­æ·»åŠ ï¼š
```python
# 4. MVSE Probe Features (NEWEST & HIGHLY EFFICIENT) â­ RECOMMENDED â­
# Multi-View Sequential Embedding: Uses 3 pooling strategies to extract robust features.
# Generates only 24 high-quality features (much fewer than traditional probe_features).
- {{"operation": "create_mvse_features"}}
```

## æ–¹æ³• 2: ä½¿ç”¨å¢å¼ºç‰ˆç±» (å®‰å…¨)

### ä½¿ç”¨ EnhancedTLAFS ç±»ï¼š
```python
from mvse_tlafs_integration import create_enhanced_tlafs_with_mvse

# åˆ›å»ºå¢å¼ºç‰ˆ T-LAFS
EnhancedTLAFS = create_enhanced_tlafs_with_mvse()

# åœ¨ main() å‡½æ•°ä¸­æ›¿æ¢åŸæ¥çš„ TLAFS_Algorithm
tlafs = EnhancedTLAFS(
    base_df=base_df,
    target_col=TARGET_COL,
    n_iterations=N_ITERATIONS,
    results_dir=results_dir
)
```

## ä¼˜åŠ¿å¯¹æ¯”

### MVSE vs ä¼ ç»Ÿ Probe Features:
- **ç‰¹å¾æ•°é‡**: 24 vs 70+ 
- **è®­ç»ƒé€Ÿåº¦**: æ›´å¿« (30 epochs vs 150 epochs)
- **è¿‡æ‹Ÿåˆé£é™©**: æ›´ä½ (æ›´å°‘ç»´åº¦)
- **é²æ£’æ€§**: æ›´å¼º (éšæœºé®ç½©æœºåˆ¶)
- **æ³›åŒ–èƒ½åŠ›**: æ›´å¥½ (å¤šè§†è§’æ± åŒ–)

## ä½¿ç”¨å»ºè®®

1. **ä¼˜å…ˆä½¿ç”¨ MVSE**: åœ¨é«˜çº§é˜¶æ®µä¼˜å…ˆæ¨è `create_mvse_features`
2. **ç»„åˆä½¿ç”¨**: å¯ä»¥ä¸ä¼ ç»Ÿç‰¹å¾å·¥ç¨‹æ–¹æ³•ç»„åˆ
3. **å‚æ•°è°ƒä¼˜**: å¯ä»¥è°ƒæ•´ `hist_len`, `num_lags`, `mask_rate` ç­‰å‚æ•°
4. **ç›‘æ§æ€§èƒ½**: è§‚å¯Ÿ MVSE ç‰¹å¾åœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„è¡¨ç°
"""
    
    return guide


if __name__ == "__main__":
    # è¿è¡Œé›†æˆæµ‹è¯•
    test_mvse_integration_in_tlafs()
    
    # æ‰“å°é›†æˆæŒ‡å—
    print("\n" + "="*80)
    print(create_integration_guide()) 