import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
from sklearn.preprocessing import MinMaxScaler
import warnings
import os

warnings.filterwarnings('ignore')

# --- æ•°æ®å¤„ç† ---
def get_time_series_data(dataset_type='min_daily_temps'):
    """ä»CSVåŠ è½½å¹¶é¢„å¤„ç†æ—¶é—´åºåˆ—æ•°æ®"""
    if dataset_type == 'min_daily_temps':
        # å‡è®¾è„šæœ¬ä¸'data'ç›®å½•åœ¨åŒä¸€çº§åˆ«
        csv_path = os.path.join('data', 'min_daily_temps.csv')
        if not os.path.exists(csv_path):
             raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ•°æ®é›† '{csv_path}'ã€‚è¯·ç¡®ä¿ 'data' æ–‡ä»¶å¤¹å’Œæ•°æ®é›†å­˜åœ¨ã€‚")
        df = pd.read_csv(csv_path)
        df.rename(columns={'Date': 'date', 'Temp': 'temp'}, inplace=True)
    else:
        raise ValueError('æœªçŸ¥çš„æ•°æ®é›†ç±»å‹')
    
    df['date'] = pd.to_datetime(df['date'])
    df.sort_values('date', inplace=True)
    df.reset_index(drop=True, inplace=True)
    return df

# --- æ¨¡å‹å®šä¹‰ (ä»ä¸»å®éªŒä¸­å¤åˆ¶) ---
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.layers = nn.Sequential(
            nn.Linear(input_size, 128), nn.ReLU(), nn.Dropout(0.2),
            nn.Linear(128, 64), nn.ReLU(), nn.Dropout(0.2),
            nn.Linear(64, 1)
        )
    def forward(self, x): return self.layers(x)

class EnhancedNN(nn.Module): # LSTM + Attention
    def __init__(self, input_size, hidden_size=64, num_layers=2):
        super(EnhancedNN, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)
        self.attention = nn.Linear(hidden_size, 1)
        self.regressor = nn.Linear(hidden_size, 1)

    def forward(self, x):
        # PyTorchçš„LSTMæœŸæœ›è¾“å…¥å½¢çŠ¶ä¸º (batch, seq, feature)ï¼Œä½†æˆ‘ä»¬çš„æ•°æ®æ˜¯ (batch, feature)
        # æˆ‘ä»¬éœ€è¦åœ¨è¾“å…¥åˆ°LSTMå‰å¢åŠ ä¸€ä¸ªåºåˆ—é•¿åº¦ç»´åº¦ (seq=1)
        lstm_out, _ = self.lstm(x.unsqueeze(1))
        # lstm_out å½¢çŠ¶: (batch, 1, hidden_size)
        attn_weights = torch.softmax(self.attention(lstm_out), dim=1)
        context = torch.bmm(lstm_out.transpose(1, 2), attn_weights).squeeze(2)
        return self.regressor(context)

class TransformerModel(nn.Module):
    def __init__(self, input_size, d_model=64, nhead=4, num_encoder_layers=2):
        super(TransformerModel, self).__init__()
        self.input_layer = nn.Linear(input_size, d_model)
        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=d_model*4, dropout=0.1, batch_first=True)
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)
        self.output_layer = nn.Linear(d_model, 1)

    def forward(self, x):
        # Transformerç¼–ç å™¨ä¹ŸæœŸæœ›åºåˆ—è¾“å…¥
        x = self.input_layer(x.unsqueeze(1)) # (batch, 1, d_model)
        x = self.transformer_encoder(x)
        x = self.output_layer(x.squeeze(1)) # (batch, 1)
        return x

# --- æ¨¡å‹è®­ç»ƒ ---
def train_pytorch_model(model, X_train, y_train, X_test):
    """ä¸€ä¸ªé€šç”¨çš„PyTorchæ¨¡å‹è®­ç»ƒå’Œé¢„æµ‹å‡½æ•°"""
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    
    dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))
    loader = DataLoader(dataset, batch_size=32, shuffle=True)
    criterion, optimizer = nn.MSELoss(), optim.Adam(model.parameters(), lr=0.001)

    model.train()
    for epoch in range(50): # å›ºå®šçš„è®­ç»ƒå‘¨æœŸ
        for inputs, targets in loader:
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()

    model.eval()
    with torch.no_grad():
        preds_tensor = model(torch.FloatTensor(X_test).to(device))
    return preds_tensor.cpu().numpy().flatten()

# --- ç‰¹å¾å·¥ç¨‹ ---
def create_kitchen_sink_features(df, target_col):
    """åˆ›å»ºä¸€å¥—'å¤§è€Œå…¨'çš„ç‰¹å¾é›†æ¥æ¨¡æ‹Ÿè¿‡åº¦çš„ç‰¹å¾å·¥ç¨‹"""
    df_out = df.copy()
    
    # æ»åç‰¹å¾
    for lag in [1, 2, 3, 7, 14, 21, 30]:
        df_out[f'lag_{lag}'] = df_out[target_col].shift(lag)
        
    # å·®åˆ†ç‰¹å¾
    for period in [1, 7, 30]:
        df_out[f'diff_{period}'] = df_out[target_col].diff(periods=period)
        
    # æ»šåŠ¨ç»Ÿè®¡ç‰¹å¾
    windows = [3, 7, 14, 30]
    for window in windows:
        rolling = df_out[target_col].rolling(window=window)
        df_out[f'rolling_mean_{window}'] = rolling.mean()
        df_out[f'rolling_std_{window}'] = rolling.std()
        df_out[f'rolling_min_{window}'] = rolling.min()
        df_out[f'rolling_max_{window}'] = rolling.max()
        df_out[f'rolling_skew_{window}'] = rolling.skew()
        df_out[f'rolling_kurt_{window}'] = rolling.kurt()
        
    # æŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡
    for span in [7, 30]:
        df_out[f'ewm_span_{span}'] = df_out[target_col].ewm(span=span, adjust=False).mean()
        
    # æ—¶é—´ç‰¹å¾
    df_out['dayofweek'] = df_out['date'].dt.dayofweek
    df_out['month'] = df_out['date'].dt.month
    df_out['weekofyear'] = df_out['date'].dt.isocalendar().week.astype(int)
    df_out['quarter'] = df_out['date'].dt.quarter
    df_out['dayofyear'] = df_out['date'].dt.dayofyear
    df_out['is_weekend'] = (df_out['date'].dt.dayofweek >= 5).astype(int)
    
    # å‚…é‡Œå¶ç‰¹å¾
    time_idx = (df_out['date'] - df_out['date'].min()).dt.days
    for period in [365.25, 30.5]:
        for k in range(1, 4): # 3é˜¶å‚…é‡Œå¶
            df_out[f'fourier_sin_{k}_{int(period)}'] = np.sin(2 * np.pi * k * time_idx / period)
            df_out[f'fourier_cos_{k}_{int(period)}'] = np.cos(2 * np.pi * k * time_idx / period)
            
    # ä¸ºæ‰€æœ‰åŸºäºç›®æ ‡å˜é‡è¡ç”Ÿçš„ç‰¹å¾è¿›è¡Œç§»ä½ï¼Œé˜²æ­¢æ•°æ®æ³„æ¼
    target_derived_cols = [col for col in df_out.columns if col not in df.columns and 'fourier' not in col and col not in ['dayofweek', 'month', 'weekofyear', 'quarter', 'dayofyear', 'is_weekend']]
    df_out[target_derived_cols] = df_out[target_derived_cols].shift(1)
    
    print(f"åˆ›å»ºäº† {len(df_out.columns) - len(df.columns)} ä¸ªæ–°ç‰¹å¾ã€‚")
    return df_out

# --- æ ¸å¿ƒè¯„ä¼°é€»è¾‘ ---
def run_evaluation(df, target_col, models_def, feature_scenario_name):
    """åœ¨ç»™å®šçš„æ•°æ®é›†ä¸Šè¿è¡Œæ‰€æœ‰æ¨¡å‹çš„è¯„ä¼°"""
    print(f"\n===== è¯„ä¼°åœºæ™¯: {feature_scenario_name} =====")
    
    # æ ¸å¿ƒä¿®å¤: ä¸å†ä½¿ç”¨ dropna()ï¼Œè€Œæ˜¯å¡«å……NaNå€¼
    # å…ˆåˆ†ç¦»å‡ºç‰¹å¾å’Œç›®æ ‡
    features = [col for col in df.columns if col not in ['date', target_col]]
    X = df[features]
    y = df[target_col]

    # ç”¨0å¡«å……ç‰¹å¾ä¸­çš„NaNã€‚è¿™æ˜¯ä¸€ç§ç®€å•è€Œç¨³å¥çš„å¤„ç†æ–¹å¼ï¼Œå¯ä»¥é¿å…åˆ é™¤è¿‡å¤šè¡Œã€‚
    X = X.fillna(0)

    # æ‰¾å‡ºç›®æ ‡yä¸­ä¸æ˜¯NaNçš„è¡Œç´¢å¼•
    valid_y_indices = y.notna()

    # åŸºäºè¿™äº›æœ‰æ•ˆç´¢å¼•æ¥è¿‡æ»¤Xå’Œyï¼Œç¡®ä¿å®ƒä»¬å¯¹é½ä¸”ä¸å«NaN
    X = X[valid_y_indices]
    y = y[valid_y_indices]

    if X.empty:
        print("è­¦å‘Š: æ²¡æœ‰å¯ä¾›è¯„ä¼°çš„ç‰¹å¾ã€‚")
        return {name: {'r2': float('nan')} for name in models_def}

    print(f"æ•°æ®å‡†å¤‡å®Œæ¯•ï¼Œä½¿ç”¨ {len(features)} ä¸ªç‰¹å¾è¿›è¡Œè®­ç»ƒã€‚")
    
    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)

    # ç‰¹å¾å’Œç›®æ ‡å€¼ç¼©æ”¾
    scaler_X = MinMaxScaler()
    X_train_s = scaler_X.fit_transform(X_train)
    X_test_s = scaler_X.transform(X_test)

    scaler_y = MinMaxScaler()
    y_train_s = scaler_y.fit_transform(y_train.values.reshape(-1, 1))

    results = {}
    for name, model_class in models_def.items():
        print(f"  -> æ­£åœ¨è¯„ä¼°æ¨¡å‹: {name}...")
        model = model_class(input_size=X.shape[1])
        
        preds_scaled = train_pytorch_model(model, X_train_s, y_train_s, X_test_s)
        preds = scaler_y.inverse_transform(preds_scaled.reshape(-1, 1)).flatten()
        
        r2 = r2_score(y_test, preds)
        results[name] = {'r2': r2}
        print(f"     - {name} RÂ² åˆ†æ•°: {r2:.4f}")
    
    return results

def main():
    """ä¸»å‡½æ•°ï¼Œæ‰§è¡Œå®Œæ•´çš„éªŒè¯æµç¨‹"""
    print("="*80)
    print("ğŸš€ å¼€å§‹éªŒè¯ 'æ¨¡å‹-ç‰¹å¾ä¸åŒ¹é…' (Model-Feature Mismatch) å‡è®¾")
    print("="*80)
    
    # 1. åŠ è½½æ•°æ®
    try:
        df_base = get_time_series_data('min_daily_temps')
        target_col = 'temp'
        print(f"æˆåŠŸåŠ è½½æ•°æ®é›†ï¼ŒåŒ…å« {len(df_base)} æ¡è®°å½•ã€‚")
    except FileNotFoundError as e:
        print(f"é”™è¯¯: {e}")
        return

    # 2. å®šä¹‰å¾…è¯„ä¼°çš„æ¨¡å‹
    models_to_test = {
        'SimpleNN': SimpleNN,
        'EnhancedNN (LSTM+Attn)': EnhancedNN,
        'Transformer': TransformerModel
    }
    
    # 3. å®éªŒä¸€: åŸå§‹æ•°æ® (ä»…ç”¨ lag_1 ä½œä¸ºæœ€åŸºç¡€ç‰¹å¾)
    df_raw = df_base.copy()
    df_raw['lag_1'] = df_raw[target_col].shift(1)
    results_raw = run_evaluation(df_raw, target_col, models_to_test, "åŸå§‹æ•°æ® (ä»… lag-1 ç‰¹å¾)")
    
    # 4. å®éªŒäºŒ: "å¤§è€Œå…¨"ç‰¹å¾é›†
    df_rich = create_kitchen_sink_features(df_base.copy(), target_col)
    results_rich = run_evaluation(df_rich, target_col, models_to_test, "'å¤§è€Œå…¨'ç‰¹å¾é›†")
    
    # 5. æ‰“å°æ€»ç»“æŠ¥å‘Š
    print("\n\n" + "="*80)
    print("ğŸ“Š å‡è®¾éªŒè¯æ€»ç»“æŠ¥å‘Š")
    print("="*80)
    print(f"{'æ¨¡å‹':<25} | {'RÂ² (åŸå§‹æ•°æ®)':<20} | {'RÂ² (å¤§è€Œå…¨ç‰¹å¾)':<20} | {'æ€§èƒ½å˜åŒ–':<15}")
    print("-"*80)
    
    for model_name in models_to_test.keys():
        r2_raw = results_raw[model_name]['r2']
        r2_rich = results_rich[model_name]['r2']
        change = r2_rich - r2_raw
        
        change_str = f"{change:+.4f}"
        if change > 0.01:
            change_str += " (æ˜¾è‘—æå‡)"
        elif change < -0.01:
            change_str += " (æ˜¾è‘—ä¸‹é™)"
        else:
            change_str += " (æ— æ˜æ˜¾å˜åŒ–)"
            
        print(f"{model_name:<25} | {r2_raw:<20.4f} | {r2_rich:<20.4f} | {change_str:<15}")
        
    print("-"*80)
    print("\nç»“è®º:")
    print("  - SimpleNN: åœ¨'å¤§è€Œå…¨'ç‰¹å¾é›†ä¸Šè¡¨ç°æ˜¯å¦æå‡ï¼Ÿ")
    print("  - EnhancedNN / Transformer: åœ¨'å¤§è€Œå…¨'ç‰¹å¾é›†ä¸Šè¡¨ç°æ˜¯å¦ä¸‹é™ï¼Ÿ")
    print("å¦‚æœä¸Šè¿°é—®é¢˜çš„ç­”æ¡ˆä¸º'æ˜¯'ï¼Œåˆ™å‡è®¾å¾—åˆ°æœ‰åŠ›æ”¯æŒã€‚")

if __name__ == "__main__":
    main() 