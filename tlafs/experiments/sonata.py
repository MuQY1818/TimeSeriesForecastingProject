"""
Sonataå®éªŒæ¨¡å— - ä½¿ç”¨é‡æ„åçš„TLAFSæ¡†æ¶
"""
import os
from datetime import datetime
import json

# ä»é‡æ„åçš„tlafsæ¡†æ¶ä¸­å¯¼å…¥å¿…è¦çš„æ¨¡å—
from tlafs.core.algorithm import TLAFS_Algorithm
from tlafs.utils.data_utils import get_time_series_data
from tlafs.features.generator import execute_plan
from tlafs.utils.evaluation import probe_feature_set, evaluate_on_multiple_models
from tlafs.visualization.plotting import visualize_final_predictions
from tlafs.utils.file_utils import save_results # å‡è®¾è¿™ä¸ªå‡½æ•°ä»ç„¶é€‚ç”¨
from tlafs.analysis.feature_importance import calculate_permutation_importance, analyze_iterative_contribution
from sklearn.model_selection import train_test_split
import lightgbm as lgb
from sklearn.metrics import r2_score
import pandas as pd

def main():
    """ä¸»å‡½æ•°ï¼Œè¿è¡Œå®Œæ•´çš„Sonata T-LAFSå®éªŒã€‚"""
    
    # ===== é…ç½®å˜é‡ =====
    DATASET_TYPE = 'min_daily_temps'
    N_ITERATIONS = 5
    TARGET_COL = 'temp'
    
    print("="*80)
    print(f"ğŸš€ T-LAFS Sonataå®éªŒ: ä½¿ç”¨æ¨¡å—åŒ–æ¡†æ¶")
    print("="*80)

    # --- 1. åˆå§‹åŒ–ç¯å¢ƒå’Œæ•°æ® ---
    run_timestamp = datetime.now().strftime("sonata_%Y%m%d_%H%M%S")
    results_dir = os.path.join("results", run_timestamp)
    os.makedirs(results_dir, exist_ok=True)
    print(f"ğŸ“‚ æœ¬æ¬¡è¿è¡Œçš„æ‰€æœ‰ç»“æœå°†ä¿å­˜åœ¨: {results_dir}")

    base_df = get_time_series_data(DATASET_TYPE)

    # --- 2. è¿è¡Œ T-LAFS ç‰¹å¾æœç´¢ ---
    tlafs_alg = TLAFS_Algorithm(
        base_df=base_df,
        target_col=TARGET_COL,
        n_iterations=N_ITERATIONS,
        results_dir=results_dir
    )
    
    # TLAFS_Algorithmçš„__init__ç°åœ¨ä¼šè‡ªåŠ¨è°ƒç”¨é¢„è®­ç»ƒ
    
    # å®šä¹‰TLAFSè¿è¡Œæ‰€éœ€çš„å‚æ•°å­—å…¸
    # è¿™äº›å‚æ•°ä¼šè¢«ä¼ é€’ç»™ execute_plan å‡½æ•°
    tlafs_params = {
        "target_col_static": tlafs_alg.target_col_static,
        "pretrain_cols_static": tlafs_alg.pretrain_cols_static,
        "pretrained_encoders": tlafs_alg.pretrained_encoders,
        "embedder_scalers": tlafs_alg.embedder_scalers,
        # å¦‚æœæœ‰å…¶ä»–æ¨¡å‹ï¼Œä¹Ÿåœ¨è¿™é‡Œæ·»åŠ 
        # "meta_forecast_models": tlafs_alg.meta_forecast_models,
        # "meta_scalers": tlafs_alg.meta_scalers,
    }

    # å°†æ‰§è¡Œå’Œæ¢æµ‹å‡½æ•°ä¼ é€’ç»™runæ–¹æ³•
    best_df, best_feature_plan, best_score_during_search = tlafs_alg.run(
        execute_plan_func=lambda df, plan, params: execute_plan(df, plan, params),
        probe_func=lambda df, target, features: probe_feature_set(df, target, features)
    )

    # --- 3. å¯¹æ‰¾åˆ°çš„æœ€ä½³ç‰¹å¾é›†è¿›è¡Œæœ€ç»ˆåˆ†æ ---
    if best_df is not None:
        probe_name_for_reporting = "Sonata_Transformer_Specialist"
        print("\n" + "="*40)
        print(f"ğŸ”¬ å¯¹æ‰€æœ‰æ¨¡å‹è¿›è¡Œæœ€ç»ˆéªŒè¯ ({probe_name_for_reporting}) ğŸ”¬")
        print("="*40)
        
        final_metrics, final_results = evaluate_on_multiple_models(
            best_df,
            TARGET_COL
        )

        if final_metrics:
            best_final_model_name = max(final_metrics, key=lambda k: final_metrics[k]['r2'])
            best_final_metrics = final_metrics[best_final_model_name]
            
            # ä»final_resultsä¸­ä¸ºæœ€ä½³æ¨¡å‹è·å–æ—¥æœŸã€çœŸå®å€¼å’Œé¢„æµ‹å€¼
            # æ³¨æ„ï¼ševaluate_on_multiple_modelsè¿”å›çš„y_testæ˜¯åˆ—è¡¨ï¼Œéœ€è¦è½¬æ¢ä¸ºpd.Seriesä»¥ä¾¿ä½¿ç”¨ç´¢å¼•
            best_result_data = final_results[best_final_model_name]
            
            # æˆ‘ä»¬éœ€è¦ä»best_dfä¸­è·å–æ­£ç¡®çš„æ—¥æœŸç´¢å¼•
            # evaluate_on_multiple_modelså†…éƒ¨è¿›è¡Œäº†train_test_splitï¼Œæˆ‘ä»¬éœ€è¦è·å–æµ‹è¯•é›†çš„ç´¢å¼•
            # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬å‡è®¾evaluate_on_multiple_modelsè¿”å›çš„y_trueçš„ç´¢å¼•ä¸best_dfçš„æµ‹è¯•éƒ¨åˆ†åŒ¹é…
            # ä¸€ä¸ªæ›´å¥å£®çš„æ–¹æ³•æ˜¯è®©è¯„ä¼°å‡½æ•°ä¹Ÿè¿”å›æµ‹è¯•ç´¢å¼•
            test_indices = best_df.index[-len(best_result_data['y_true']):]


            visualize_final_predictions(
                dates=best_df.loc[test_indices, 'date'],
                y_true=best_result_data['y_true'],
                y_pred=best_result_data['y_pred'],
                best_model_name=best_final_model_name,
                probe_name=probe_name_for_reporting,
                best_model_metrics=best_final_metrics,
                results_dir=results_dir
            )

            # --- 3.5. ç‰¹å¾é‡è¦æ€§åˆ†æ ---
            print("\n" + "="*40)
            print(f"ğŸ”¬ ç‰¹å¾é‡è¦æ€§åˆ†æ ğŸ”¬")
            print("="*40)

            # a) è¿­ä»£è¾¹é™…è´¡çŒ®åˆ†æ
            print("\n--- è¿­ä»£è¾¹é™…è´¡çŒ® (Iterative Marginal Contribution) ---")
            print("æ­¤åˆ†ææ˜¾ç¤ºäº†åœ¨T-LAFSæœç´¢è¿‡ç¨‹ä¸­ï¼ŒæŒ‰é¡ºåºæ·»åŠ æ¯ä¸ªç‰¹å¾æ—¶æ¨¡å‹æ€§èƒ½çš„å˜åŒ–ã€‚")
            iterative_contribution_df = analyze_iterative_contribution(tlafs_alg.history)
            if not iterative_contribution_df.empty:
                print(iterative_contribution_df.to_string())
                # ä¿å­˜åˆ°CSV
                iterative_contribution_path = os.path.join(results_dir, "iterative_contribution.csv")
                iterative_contribution_df.to_csv(iterative_contribution_path, index=False)
                print(f"\nâœ… è¿­ä»£è´¡çŒ®åˆ†æå·²ä¿å­˜è‡³: {iterative_contribution_path}")

            # b) æ’åˆ—é‡è¦æ€§åˆ†æ
            print("\n--- æ’åˆ—é‡è¦æ€§ (Permutation Importance) ---")
            print("æ­¤åˆ†ææ˜¾ç¤ºäº†åœ¨æœ€ç»ˆæ¨¡å‹ä¸­ï¼Œéšæœºæ‰“ä¹±æ¯ä¸ªç‰¹å¾åå¯¹æ¨¡å‹æ€§èƒ½ï¼ˆR^2ï¼‰é€ æˆçš„è´Ÿé¢å½±å“ã€‚")
            
            # ä¸ºäº†è¿›è¡Œæ­¤åˆ†æï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹å’ŒéªŒè¯é›†
            # æˆ‘ä»¬å°†ä½¿ç”¨LightGBMï¼Œå› ä¸ºå®ƒé€Ÿåº¦å¿«ä¸”æ€§èƒ½å¥½
            features = [col for col in best_df.columns if col not in ['date', TARGET_COL]]
            X = best_df[features]
            y = best_df[TARGET_COL]

            # ç®€å•æ‹†åˆ†æ•°æ®ç”¨äºåˆ†æ
            X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

            # è®­ç»ƒä¸€ä¸ªLGBMæ¨¡å‹
            lgbm_for_importance = lgb.LGBMRegressor(random_state=42)
            lgbm_for_importance.fit(X_train, y_train)

            # è®¡ç®—æ’åˆ—é‡è¦æ€§
            permutation_importance_df = calculate_permutation_importance(
                model=lgbm_for_importance,
                X_val=X_val,
                y_val=y_val,
                metric_func=r2_score
            )
            print(permutation_importance_df.to_string())

            # ä¿å­˜åˆ°CSV
            perm_importance_path = os.path.join(results_dir, "permutation_importance.csv")
            permutation_importance_df.to_csv(perm_importance_path)
            print(f"\nâœ… æ’åˆ—é‡è¦æ€§åˆ†æå·²ä¿å­˜è‡³: {perm_importance_path}")

            # --- 3.6. åŸºäºé‡è¦æ€§çš„æœ€ç»ˆç‰¹å¾å‰ªæ ---
            print("\n========================================\nğŸ”ª åŸºäºé‡è¦æ€§çš„æœ€ç»ˆç‰¹å¾å‰ªæ ğŸ”ª\n========================================")
            PRUNING_THRESHOLD = 0.0
            print(f"å‰ªæé˜ˆå€¼ (Permutation Importance): <= {PRUNING_THRESHOLD}")
            
            # è·å–ä½é‡è¦æ€§ç‰¹å¾
            features_to_drop = permutation_importance_df[
                permutation_importance_df['importance_mean'] <= PRUNING_THRESHOLD
            ].index.tolist()
            
            if features_to_drop:
                print(f"\nå°†åˆ é™¤ä»¥ä¸‹ä½é‡è¦æ€§ç‰¹å¾:")
                for feature in features_to_drop:
                    print(f"  - {feature}")
                
                # åˆ é™¤ä½é‡è¦æ€§ç‰¹å¾
                df_pruned = best_df.copy()
                df_pruned = df_pruned.drop(columns=features_to_drop)
                
                # é‡æ–°è¯„ä¼°æ¨¡å‹æ€§èƒ½
                print("\né‡æ–°è¯„ä¼°å‰ªæåçš„æ¨¡å‹æ€§èƒ½...")
                X_pruned = df_pruned.drop(columns=[TARGET_COL, 'date'])
                y_pruned = df_pruned[TARGET_COL]
                
                # ä½¿ç”¨LightGBMè¯„ä¼°
                lgb_model = lgb.LGBMRegressor(random_state=42)
                lgb_model.fit(X_pruned, y_pruned)
                y_pred_pruned = lgb_model.predict(X_pruned)
                r2_pruned = r2_score(y_pruned, y_pred_pruned)
                
                print(f"\nå‰ªæåçš„æ€§èƒ½:")
                print(f"  - ç‰¹å¾æ•°é‡: {len(X_pruned.columns)} (å‡å°‘äº† {len(features_to_drop)} ä¸ªç‰¹å¾)")
                print(f"  - RÂ² åˆ†æ•°: {r2_pruned:.4f}")
                
                # å¦‚æœæ€§èƒ½æ²¡æœ‰æ˜¾è‘—ä¸‹é™ï¼Œä½¿ç”¨å‰ªæåçš„ç‰¹å¾é›†
                if r2_pruned >= best_final_metrics['r2'] - 0.01:  # å…è®¸0.01çš„æ€§èƒ½ä¸‹é™
                    print("\nâœ… é‡‡ç”¨å‰ªæåçš„ç‰¹å¾é›†")
                    best_df = df_pruned
                    best_final_metrics = final_metrics[max(final_metrics, key=lambda k: final_metrics[k]['r2'])]
                    best_result_data = final_results[max(final_metrics, key=lambda k: final_metrics[k]['r2'])]
                else:
                    print("\nâŒ ä¿æŒåŸå§‹ç‰¹å¾é›†")
            else:
                print("\næ²¡æœ‰å‘ç°éœ€è¦åˆ é™¤çš„ä½é‡è¦æ€§ç‰¹å¾")

            # --- 4. ä¿å­˜æ‰€æœ‰ç»“æœ ---
            # ä»è¿™é‡Œå¼€å§‹ï¼Œä½¿ç”¨æœ€ç»ˆå†³ç­–çš„å˜é‡ (best_df, best_final_metrics, etc.)
            best_final_metrics_after_pruning = best_final_metrics
            best_result_data_after_pruning = best_result_data
            
            # é‡æ–°è·å–æµ‹è¯•é›†ç´¢å¼•ï¼Œä»¥é˜²å‰ªæåçš„dfé•¿åº¦å˜åŒ–
            test_indices_after_pruning = best_df.index[-len(best_result_data['y_true']):]

            visualize_final_predictions(
                dates=best_df.loc[test_indices_after_pruning, 'date'],
                y_true=best_result_data['y_true'],
                y_pred=best_result_data['y_pred'],
                best_model_name=best_final_model_name,
                probe_name=probe_name_for_reporting,
                best_model_metrics=best_final_metrics_after_pruning,
                results_dir=results_dir
            )

            summary_data = {
                "probe_model": probe_name_for_reporting,
                "best_score_during_search": best_score_during_search,
                "best_feature_plan": best_feature_plan,
                "final_features": [col for col in best_df.columns if col not in ['date', TARGET_COL]],
                "final_validation_scores": best_final_metrics,
                "best_final_model": {
                    "name": best_final_model_name,
                    "metrics": best_final_metrics_after_pruning
                },
                "run_history": tlafs_alg.history
            }
            
            # ä½¿ç”¨ä¸€ä¸ªé€šç”¨çš„JSONä¿å­˜å‡½æ•°
            results_path = os.path.join(results_dir, "sonata_tlafs_summary.json")
            with open(results_path, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, indent=4, default=str) # ä½¿ç”¨default=strå¤„ç†Numpyç±»å‹
            print(f"âœ… æœ€ç»ˆæ€»ç»“å·²ä¿å­˜è‡³: {results_path}")

    else:
        print("\nT-LAFSæœªèƒ½æ‰¾åˆ°æœ‰æ•ˆçš„ç‰¹å¾è®¡åˆ’ã€‚")

if __name__ == "__main__":
    main()