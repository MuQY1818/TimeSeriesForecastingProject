import pandas as pd
import numpy as np
import torch

# å‡è®¾ç›¸å…³çš„æ¨¡å‹å’Œå‡½æ•°å¯ä»¥ä»æ¡†æ¶çš„å…¶ä»–éƒ¨åˆ†å¯¼å…¥
# from ..models.autoencoder import MaskedEncoder
# from ..models.probe import ProbeForecaster
# from .mvse import generate_mvse_features_for_tlafs

# åœ¨å®é™…åº”ç”¨ä¸­ï¼Œä¸‹é¢çš„TLAFS_Algorithmå±æ€§éœ€è¦è¢«æ­£ç¡®è®¾ç½®æˆ–ä¼ å…¥
# TLAFS_Algorithm.pretrained_encoders = {}
# TLAFS_Algorithm.embedder_scalers = {}
# TLAFS_Algorithm.meta_forecast_models = {}
# TLAFS_Algorithm.meta_scalers = {}
# TLAFS_Algorithm.probe_config = {}
# TLAFS_Algorithm.probe_model_path = ""
# TLAFS_Algorithm.pretrain_cols_static = []
# TLAFS_Algorithm.target_col_static = ""

def execute_plan(df: pd.DataFrame, plan: list, tlafs_params: dict):
    """
    åœ¨ä¸€ä¸ªç»™å®šçš„DataFrameä¸Šæ‰§è¡Œç‰¹å¾å·¥ç¨‹è®¡åˆ’ã€‚
    è¿™æ˜¯æ‰€æœ‰ç‰¹å¾ç”Ÿæˆçš„å•ä¸€ã€æƒå¨çš„é™æ€æ–¹æ³•ã€‚
    å®ƒåŒ…å«äº†æ‰€æœ‰æ— æ³„æ¼çš„ç‰¹å¾ç”Ÿæˆé€»è¾‘ã€‚
    """
    temp_df = df.copy()
    new_feature_name = None # ç”¨äºè·Ÿè¸ªæ–°ç”Ÿæˆçš„ç‰¹å¾

    # ä»ä¼ å…¥çš„å­—å…¸ä¸­è·å–å¿…è¦çš„å‚æ•°
    target_col = tlafs_params.get("target_col_static")
    pretrained_encoders = tlafs_params.get("pretrained_encoders", {})
    embedder_scalers = tlafs_params.get("embedder_scalers", {})
    meta_forecast_models = tlafs_params.get("meta_forecast_models", {})
    meta_scalers = tlafs_params.get("meta_scalers", {})
    # ... å…¶ä»–éœ€è¦çš„å‚æ•° ...

    required_time_cols = ['dayofweek', 'month', 'weekofyear', 'is_weekend']
    if not all(col in temp_df.columns for col in required_time_cols):
        # ... (ç¡®ä¿åŸºç¡€æ—¶é—´ç‰¹å¾å­˜åœ¨çš„é€»è¾‘) ...
        pass
    
    # --- æ ¸å¿ƒä¿®æ”¹ï¼šç¡®ä¿planæ˜¯ä¸€ä¸ªåˆ—è¡¨ ---
    if not isinstance(plan, list):
        plan = [plan] # å¦‚æœplanæ˜¯å•ä¸ªå­—å…¸ï¼Œå°†å…¶åŒ…è£…åœ¨åˆ—è¡¨ä¸­

    executed_feature_names = []

    for step in plan:
        op = None
        try:
            op = step.get("function")
            args = step.get("args", {})
            
            # ç”¨äºè®°å½•å½“å‰æ­¥éª¤ç”Ÿæˆç‰¹å¾çš„ä¸´æ—¶å˜é‡
            step_feature_name = None

            # --- æ–°å¢çš„å®åŠŸèƒ½ ---
            if op == "create_control_baseline_features":
                print("  - æ­£åœ¨æ‰§è¡Œå®æ“ä½œ: create_control_baseline_features...")
                target = args.get("col", target_col)
                
                # 1. æ—¶é—´ç‰¹å¾ (ä¸control.pyä¸€è‡´)
                temp_df['year'] = pd.to_datetime(temp_df['date']).dt.year
                temp_df['month'] = pd.to_datetime(temp_df['date']).dt.month
                temp_df['day'] = pd.to_datetime(temp_df['date']).dt.day
                temp_df['dayofweek'] = pd.to_datetime(temp_df['date']).dt.dayofweek
                
                # 2. æ»åç‰¹å¾
                for lag in [1, 2, 3, 7, 14]:
                    temp_df[f'{target}_lag_{lag}'] = temp_df[target].shift(lag)
                
                # 3. æ»šåŠ¨ç»Ÿè®¡ç‰¹å¾
                for window in [7, 14, 30]:
                    temp_df[f'{target}_rolling_mean_{window}'] = temp_df[target].rolling(window=window).mean().shift(1)
                    temp_df[f'{target}_rolling_std_{window}'] = temp_df[target].rolling(window=window).std().shift(1)
                    temp_df[f'{target}_rolling_min_{window}'] = temp_df[target].rolling(window=window).min().shift(1)
                    temp_df[f'{target}_rolling_max_{window}'] = temp_df[target].rolling(window=window).max().shift(1)
                
                # ç”±äºåˆ›å»ºäº†å¤§é‡æ»åå’Œæ»šåŠ¨ç‰¹å¾ï¼Œä¼šå¼•å…¥NaNï¼Œè¿™é‡Œæˆ‘ä»¬ç”¨0å¡«å……
                # è¿™ä¸control.pyä¸­çš„dropna()è¡Œä¸ºä¸åŒï¼Œä½†æ›´ç¬¦åˆT-LAFSçš„è¿­ä»£æ€§è´¨
                temp_df.fillna(0, inplace=True)
                
                # å¯¹äºå®æ“ä½œï¼Œæˆ‘ä»¬è¿”å›ä¸€ä¸ªæè¿°æ€§çš„åå­—
                step_feature_name = "control_baseline_features_set"
                print("  - âœ… æˆåŠŸç”Ÿæˆäº†controlåŸºçº¿ç‰¹å¾é›†ã€‚")

            # --- åŸºç¡€æ—¶åºç‰¹å¾ ---
            elif op == "create_lag_features":
                col = args.get("col")
                lags = args.get("lags", [1])
                for lag in lags:
                    step_feature_name = f"{col}_lag_{lag}"
                    temp_df[step_feature_name] = temp_df[col].shift(lag).ffill().fillna(0)

            elif op == "create_rolling_features":
                col = args.get("col")
                windows = args.get("windows", [7])
                aggs = args.get("aggs", ['mean'])
                for window in windows:
                    for agg in aggs:
                        step_feature_name = f"{col}_rolling_{agg}_{window}"
                        temp_df[step_feature_name] = temp_df[col].rolling(window=window).agg(agg).shift(1).ffill().fillna(0)

            elif op == "create_interaction_features":
                col1 = args.get("col1")
                col2 = args.get("col2")
                # --- æ•°æ®æ³„éœ²é˜²ç«å¢™ ---
                if col1 == target_col or col2 == target_col:
                    print(f"  - ğŸ›‘ æ•°æ®æ³„éœ²è­¦å‘Š: äº¤äº’ç‰¹å¾ä¸èƒ½ç›´æ¥ä½¿ç”¨åŸå§‹ç›®æ ‡åˆ— ('{target_col}')ã€‚è·³è¿‡æ­¤æ­¥éª¤ã€‚")
                    continue
                
                if col1 in temp_df.columns and col2 in temp_df.columns:
                    step_feature_name = f"{col1}_x_{col2}"
                    temp_df[step_feature_name] = temp_df[col1] * temp_df[col2]
                else:
                    print(f"  - âš ï¸ äº¤äº’ç‰¹å¾çš„åˆ—ä¸å­˜åœ¨: {col1} or {col2}ã€‚è·³è¿‡æ­¤æ­¥éª¤ã€‚")
                    continue
            
            elif op == "create_fourier_features":
                col = args.get("col")
                order = int(args.get("order", 1))
                if col != 'date' or col not in temp_df.columns:
                    print(f"  - âš ï¸ å‚…é‡Œå¶ç‰¹å¾å¿…é¡»åŸºäº'date'åˆ—ã€‚è·³è¿‡æ­¤æ­¥éª¤ã€‚")
                    continue
                
                print(f"  - æ­£åœ¨ä¸º '{col}' åˆ›å»º {order} é˜¶å‚…é‡Œå¶ç‰¹å¾...")
                day_of_year = pd.to_datetime(temp_df[col]).dt.dayofyear
                year_length = 365.25
                
                for k in range(1, order + 1):
                    sin_col = f"fourier_sin_{k}"
                    cos_col = f"fourier_cos_{k}"
                    temp_df[sin_col] = np.sin(2 * np.pi * k * day_of_year / year_length)
                    temp_df[cos_col] = np.cos(2 * np.pi * k * day_of_year / year_length)
                
                # å¯¹äºå¤šç‰¹å¾æ“ä½œï¼Œè¿”å›ä¸€ä¸ªæè¿°æ€§åç§°
                step_feature_name = f"fourier_features_order_{order}"

            elif op == "delete_features":
                cols_to_delete = args.get("cols", [])
                if not isinstance(cols_to_delete, list):
                    cols_to_delete = [cols_to_delete]
                
                existing_cols = [c for c in cols_to_delete if c in temp_df.columns]
                if existing_cols:
                    print(f"  - æ­£åœ¨åˆ é™¤ç‰¹å¾: {existing_cols}")
                    temp_df.drop(columns=existing_cols, inplace=True)
                    step_feature_name = f"deleted_{len(existing_cols)}_features"
                else:
                    print(f"  - âš ï¸ æƒ³è¦åˆ é™¤çš„ç‰¹å¾ä¸å­˜åœ¨: {cols_to_delete}ã€‚è·³è¿‡æ­¤æ­¥éª¤ã€‚")
                    continue

            # --- ä» specialist_tlafs_experiment.py ä¸­æ·»åŠ æ‰€æœ‰å…¶ä»–ç‰¹å¾ç”Ÿæˆé€»è¾‘ ---
            # ... ä¾‹å¦‚: create_diff, create_ewm, 
            # ... create_time_features, create_fourier_features,
            # ... create_embedding_features, create_forecast_feature, etc.
            
            elif op == "create_embedding_features": # åŒæ ·æ›´æ–°ä¸ºæ–°çš„å‡½æ•°/å‚æ•°æ ¼å¼
                col = args.get("col") # è™½ç„¶æœªä½¿ç”¨ï¼Œä½†ä¿æŒä¸€è‡´æ€§
                window_size = args.get("window_size", 90)
                
                embedder = pretrained_encoders.get(window_size)
                scaler = embedder_scalers.get(window_size)

                if embedder and scaler:
                    pretrain_cols = tlafs_params.get("pretrain_cols_static", [])
                    
                    if not all(c in temp_df.columns for c in pretrain_cols):
                         temp_df['dayofweek'] = temp_df['date'].dt.dayofweek
                         temp_df['month'] = temp_df['date'].dt.month
                         temp_df['weekofyear'] = temp_df['date'].dt.isocalendar().week.astype(int)
                         temp_df['is_weekend'] = (temp_df['date'].dt.dayofweek >= 5).astype(int)

                    print(f"  - æ­£åœ¨ä» {len(pretrain_cols)} ä¸ªç‰¹å¾ç”Ÿæˆå¤šå˜é‡åµŒå…¥ (çª—å£:{window_size})...")
                    df_for_embedding = temp_df[pretrain_cols]
                    scaled_features = scaler.transform(df_for_embedding)
                    
                    sequences = np.array([scaled_features[i:i+window_size] for i in range(len(scaled_features) - window_size + 1)])
                    
                    if sequences.size == 0:
                        print(f"  - âš ï¸ æ•°æ®ä¸è¶³ä»¥åˆ›å»ºçª—å£ä¸º {window_size} çš„åµŒå…¥ã€‚è·³è¿‡ã€‚")
                        continue
                        
                    tensor = torch.FloatTensor(sequences)
                    with torch.no_grad():
                        embeddings = embedder(tensor).numpy()
                        
                    valid_indices = temp_df.index[window_size-1:]
                    # ç”±äºå¯èƒ½ä¸€æ¬¡æ€§ç”Ÿæˆå¤šä¸ªç‰¹å¾ï¼Œæˆ‘ä»¬åªå°†ç¬¬ä¸€ä¸ªä½œä¸º"æ–°ç‰¹å¾"è¿”å›ä»¥ä¾›è®°å½•
                    cols = [f"embed_{i}_win{window_size}" for i in range(embeddings.shape[1])]
                    step_feature_name = cols[0]
                    
                    embed_df = pd.DataFrame(embeddings, index=valid_indices, columns=cols)
                    
                    existing_cols_to_drop = [c for c in cols if c in temp_df.columns]
                    if existing_cols_to_drop:
                        temp_df.drop(columns=existing_cols_to_drop, inplace=True)

                    temp_df = temp_df.join(embed_df)
                    temp_df[cols] = temp_df[cols].shift(1).ffill().fillna(0)
                else:
                    print(f"  - âš ï¸ çª—å£ {window_size} çš„åµŒå…¥å™¨ä¸å¯ç”¨ã€‚è·³è¿‡æ­¤æ­¥éª¤ã€‚")
                    continue

            # --- å…¶ä»–æ“ä½œçš„elifå— ---
            else:
                print(f"  - âš ï¸ æœªçŸ¥çš„æ“ä½œ: {op}ã€‚è·³è¿‡æ­¤æ­¥éª¤ã€‚")
                continue
            
            # å¦‚æœæ­¥éª¤æˆåŠŸï¼Œè®°å½•å…¶åç§°
            if step_feature_name:
                executed_feature_names.append(step_feature_name)

        except Exception as e:
            import traceback
            print(f"  - âŒ æ‰§è¡Œæ­¥éª¤ {step} æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯ï¼Œå·²è·³è¿‡ã€‚é”™è¯¯: {e}\n{traceback.format_exc()}")
            continue
    
    # æœ€ç»ˆè¿”å›é€»è¾‘
    if not df.equals(temp_df) and executed_feature_names:
        # å¦‚æœDataframeæœ‰å˜åŒ–ï¼Œå¹¶ä¸”æˆ‘ä»¬æˆåŠŸæ‰§è¡Œäº†è‡³å°‘ä¸€ä¸ªæ­¥éª¤
        final_name = ", ".join(executed_feature_names)
        return temp_df, final_name
    else:
        # å¦‚æœè®¡åˆ’ä¸ºç©ºï¼Œæˆ–æ‰€æœ‰æ­¥éª¤éƒ½å¤±è´¥/è·³è¿‡
        print("  - âš ï¸ è®¡åˆ’æ‰§è¡ŒåæœªæˆåŠŸç”Ÿæˆä»»ä½•æ–°ç‰¹å¾ã€‚")
        return None, None

    return temp_df 