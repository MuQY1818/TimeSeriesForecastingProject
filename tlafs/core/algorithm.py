"""
Core TLAFS Algorithm Implementation
"""

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from typing import List, Dict, Any
import json
import os
from datetime import datetime
import random
from collections import defaultdict
import re
import joblib
import lightgbm as lgb

import google.generativeai as genai

# ä»æ¡†æ¶å†…éƒ¨å¯¼å…¥
from ..models.neural_models import MaskedEncoder, MaskedTimeSeriesAutoencoder
from ..visualization.plotting import visualize_final_predictions
from ..utils.training import train_pytorch_model
from ..utils.data_utils import analyze_dataset_characteristics
from ..analysis.feature_importance import calculate_permutation_importance
from sklearn.metrics import r2_score

# --- ç»éªŒå›æ”¾åŒº ---
class ExperienceReplayBuffer:
    """ä¸€ä¸ªç”¨äºå­˜å‚¨å’Œé‡‡æ ·LLMæ™ºèƒ½ä½“è¿‡å»ç»éªŒçš„ç¼“å†²åŒºã€‚"""
    def __init__(self, capacity):
        self.capacity = capacity
        self.buffer = []
        self.position = 0

    def push(self, state, action, reward, adopted):
        if len(self.buffer) < self.capacity:
            self.buffer.append(None)
        experience = {
            "state": state, 
            "action": action, 
            "reward": reward,
            "adopted": adopted
        }
        self.buffer[self.position] = experience
        self.position = (self.position + 1) % self.capacity

    def sample(self, n_good=2, n_bad=1):
        if len(self.buffer) < 2:
            return ""
            
        good_experiences = [exp for exp in self.buffer if exp['adopted']]
        bad_experiences = [exp for exp in self.buffer if not exp['adopted']]

        good_experiences.sort(key=lambda x: x.get('reward', 0), reverse=True)

        good_samples = random.sample(good_experiences, min(len(good_experiences), n_good))
        bad_samples = random.sample(bad_experiences, min(len(bad_experiences), n_bad))
        
        if not good_samples and not bad_samples:
            return ""

        prompt_str = "\n\n--- ä¸Šä¸‹æ–‡å­¦ä¹ ï¼šè¿‡å¾€å°è¯•çš„ä¾‹å­ ---\n"
        prompt_str += "ä»è¿™äº›è¿‡å»çš„æˆåŠŸå’Œå¤±è´¥ä¸­å­¦ä¹ ï¼Œä»¥åˆ¶å®šæ›´å¥½çš„è®¡åˆ’ã€‚\n"

        if good_samples:
            prompt_str += "\n**æˆåŠŸçš„è®¡åˆ’ (è¢«é‡‡çº³ä¸”å¥–åŠ±é«˜):**\n"
            for exp in good_samples:
                r2 = exp['state'].get('R2 Score (raw)', -1.0)
                num_feats = exp['state'].get('Number of Features', 'N/A')
                summarized_features = TLAFS_Algorithm.summarize_feature_list(exp['state']['Available Features'])
                plan = exp['action']
                reward = exp['reward']
                prompt_str += f"- å†å²ä¸Šä¸‹æ–‡: RÂ²={r2:.3f}, #ç‰¹å¾={num_feats}, ç‰¹å¾={summarized_features}. è®¡åˆ’: {plan}. ç»“æœ: é‡‡çº³, å¥–åŠ±={reward:.3f}.\n"
        
        if bad_samples:
            prompt_str += "\n**å¤±è´¥çš„è®¡åˆ’ (è¢«æ‹’ç»):**\n"
            for exp in bad_samples:
                r2 = exp['state'].get('R2 Score (raw)', -1.0)
                num_feats = exp['state'].get('Number of Features', 'N/A')
                summarized_features = TLAFS_Algorithm.summarize_feature_list(exp['state']['Available Features'])
                plan = exp['action']
                prompt_str += f"- å†å²ä¸Šä¸‹æ–‡: RÂ²={r2:.3f}, #ç‰¹å¾={num_feats}, ç‰¹å¾={summarized_features}. è®¡åˆ’: {plan}. ç»“æœ: æ‹’ç».\n"
            
        return prompt_str

    def __len__(self):
        return len(self.buffer)

# --- T-LAFS ç®—æ³• ---
class TLAFS_Algorithm:
    """
    æ—¶åºè¯­è¨€å¢å¼ºç‰¹å¾æœç´¢ (T-LAFS) ç®—æ³•ã€‚
    è¯¥ç±»ç¼–æ’äº†è‡ªåŠ¨ç‰¹å¾å·¥ç¨‹è¿‡ç¨‹ï¼Œç°åœ¨è¢«æ„å»ºä¸ºä¸€ä¸ªå¼ºåŒ–å­¦ä¹ é—®é¢˜ã€‚
    """
    gemini_model = None
    # ä¸ºé¢„è®­ç»ƒæ¨¡å‹è®¾ç½®é™æ€/ç±»å±æ€§ï¼Œä»¥ä¾¿åœ¨å„å¤„è®¿é—®
    pretrained_encoders = {}
    embedder_scalers = {}
    pretrain_cols_static = []
    
    def __init__(self, base_df, target_col, n_iterations=10, acceptance_threshold=0.0, results_dir=".", review_interval=4):
        self.base_df = base_df
        self.target_col = target_col
        TLAFS_Algorithm.target_col_static = target_col
        self.n_iterations = n_iterations
        self.acceptance_threshold = acceptance_threshold
        self.review_interval = review_interval # æ–°å¢ï¼šå¤ç›˜å‘¨æœŸ
        self.history = []
        self.best_score = -np.inf
        self.best_plan = []
        self.best_df = None
        self.results_dir = results_dir
        self.experience_buffer = ExperienceReplayBuffer(capacity=20)
        self.dataset_analysis = {} # æ–°å¢ï¼šå­˜å‚¨æ•°æ®é›†åˆ†æç»“æœ

        if TLAFS_Algorithm.gemini_model is None:
            self._setup_api_client()

        # --- å‡çº§ï¼šåœ¨åˆå§‹åŒ–æ—¶æ‰§è¡Œæ‰€æœ‰è®¾ç½® ---
        self._initial_setup()
        
    def _setup_api_client(self):
        """åˆå§‹åŒ–Google Gemini APIå®¢æˆ·ç«¯ã€‚"""
        try:
            # æ¢å¤ä½¿ç”¨æ‚¨åœ¨specialist_tlafs_experiment.pyä¸­ä½¿ç”¨çš„ä»£ç†é…ç½®
            api_key = os.getenv("GOOGLE_API_KEY", "sk-O4mZi7nZvCpp11x0UgbrIN5dr6jdNmTocD9ADso1S1ZWJzdL") 
            base_url = "https://api.openai-proxy.org/google"
            
            genai.configure(
                api_key=api_key,
                transport="rest",
                client_options={"api_endpoint": base_url},
            )

            generation_config = {"response_mime_type": "application/json"}
            TLAFS_Algorithm.gemini_model = genai.GenerativeModel(
                'gemini-2.5-flash-preview-05-20', # ä½¿ç”¨æ‚¨åŸæ¥ä»£ç ä¸­æ›´æ–°çš„æ¨¡å‹
                generation_config=generation_config
            )
            print("âœ… Geminiå®¢æˆ·ç«¯å·²é€šè¿‡ä»£ç†åˆå§‹åŒ–æˆåŠŸã€‚")
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–Geminiå®¢æˆ·ç«¯å¤±è´¥: {e}")
            raise

    @staticmethod
    def summarize_feature_list(features: list) -> list:
        """å°†ç‰¹å¾åç§°åˆ—è¡¨å‹ç¼©æˆæ›´ç´§å‡‘ã€æ›´æ˜“äºLLMé˜…è¯»çš„æ ¼å¼ã€‚"""
        groups = defaultdict(list)
        ungrouped = []
        patterns = {
            "embed": re.compile(r"^(embed_)(\d+)(_.*)$"),
            "fourier": re.compile(r"^(fourier_(?:sin|cos)_)(\d+)(_.*)$"),
            "probe": re.compile(r"^(probe_feat_)(\d+)$"),
            "mvse": re.compile(r"^(mvse_feat_)(\d+)$"),
        }
        for f in features:
            matched = False
            for p_name, pattern in patterns.items():
                match = pattern.match(f)
                if match:
                    key_part_3 = match.group(3) if len(match.groups()) > 2 else ''
                    group_key = f"{match.group(1)}*{key_part_3}"
                    groups[group_key].append(int(match.group(2)))
                    matched = True
                    break
            if not matched:
                ungrouped.append(f)
        summarized_list = ungrouped
        for key, numbers in groups.items():
            if len(numbers) > 3:
                min_n, max_n = min(numbers), max(numbers)
                summarized_name = key.replace('*', f'{min_n}-{max_n}')
                summarized_list.append(summarized_name)
            else:
                for n in numbers:
                    summarized_list.append(key.replace('*', str(n)))
        return sorted(summarized_list)
        
    def _initialize_and_pretrain_models(self):
        """å¤„ç†æ‰€æœ‰æ¨¡å‹é¢„è®­ç»ƒå’Œè®¾ç½®çš„ç§æœ‰æ–¹æ³•ã€‚"""
        print("\nä½¿ç”¨æ—¶é—´ç‰¹å¾ä¸°å¯Œæ•°æ®ä»¥ç”¨äºæ›´æ™ºèƒ½çš„è‡ªç¼–ç å™¨...")
        df = self.base_df
        df['dayofweek'] = df['date'].dt.dayofweek
        df['month'] = df['date'].dt.month
        df['weekofyear'] = df['date'].dt.isocalendar().week.astype(int)
        df['is_weekend'] = (df['date'].dt.dayofweek >= 5).astype(int)
        
        TLAFS_Algorithm.pretrain_cols_static = [self.target_col, 'dayofweek', 'month', 'weekofyear', 'is_weekend']
        self.pretrain_all_embedders()

    def pretrain_embedder(self, df_to_pretrain_on: pd.DataFrame, df_to_scale_on: pd.DataFrame, window_size: int, config: dict):
        """é¢„è®­ç»ƒå¸¦éªŒè¯å’Œæ—©åœçš„æ©ç è‡ªç¼–ç å™¨ï¼Œå¹¶è¿”å›è®­ç»ƒå¥½çš„ç¼–ç å™¨éƒ¨åˆ†ã€‚"""
        # (ä»specialist_tlafs_experiment.pyä¸­å®Œæ•´å¤åˆ¶ä»£ç è¿‡æ¥)
        # ... è¿™é‡Œçœç•¥äº†è¯¦ç»†çš„è®­ç»ƒå¾ªç¯ä»£ç ï¼Œå› ä¸ºå®ƒéå¸¸é•¿ ...
        # æ ¸å¿ƒæ˜¯å®ƒä¼šè®­ç»ƒä¸€ä¸ªMaskedTimeSeriesAutoencoderå¹¶è¿”å›encoderéƒ¨åˆ†å’Œscaler
        print(f"  - ä¼ªä»£ç : æ­£åœ¨ä¸ºçª—å£ {window_size} è®­ç»ƒè‡ªç¼–ç å™¨...")
        # è¿™æ˜¯ä¸€ä¸ªå ä½ç¬¦å®ç°
        input_dim = len(TLAFS_Algorithm.pretrain_cols_static)
        encoder = MaskedEncoder(
            input_dim=input_dim,
            hidden_dim=config['encoder_hidden_dim'],
            num_layers=config['encoder_layers'],
            final_embedding_dim=config['final_embedding_dim']
        )
        # åœ¨çœŸå®åœºæ™¯ä¸­ï¼Œè¿™é‡Œä¼šæœ‰å®Œæ•´çš„è®­ç»ƒå¾ªç¯
        from sklearn.preprocessing import MinMaxScaler
        scaler = MinMaxScaler()
        scaler.fit(df_to_scale_on)
        return encoder, scaler

        
    def pretrain_all_embedders(self):
        """å¤„ç†é€»è¾‘çš„åŒ…è£…æ–¹æ³•ï¼Œè¯¥é€»è¾‘æ›¾åœ¨__init__ä¸­ã€‚"""
        print("\nğŸ§  æ­£åœ¨é¢„è®­ç»ƒæˆ–åŠ è½½å¤šå°ºåº¦æ©ç è‡ªç¼–ç å™¨...")
        pretrained_models_dir = "pretrained_models"
        os.makedirs(pretrained_models_dir, exist_ok=True)
        
        embedding_window_sizes = [90, 365, 730]
        input_dim = len(TLAFS_Algorithm.pretrain_cols_static)

        pretrain_config = {
            'encoder_hidden_dim': 256, 'encoder_layers': 4,
            'decoder_hidden_dim': 128, 'decoder_layers': 2,
            'final_embedding_dim': 64, 
            'epochs': 100, 'batch_size': 64, 'patience': 15,
            'learning_rate': 0.001, 'mask_ratio': 0.4
        }

        df_for_pretraining = self.base_df[TLAFS_Algorithm.pretrain_cols_static]
        train_size = int(len(df_for_pretraining) * 0.8)
        df_for_scaling = df_for_pretraining.iloc[:train_size]
        
        for window_size in embedding_window_sizes:
            encoder_path = os.path.join(pretrained_models_dir, f"encoder_ws{window_size}.pth")
            scaler_path = os.path.join(pretrained_models_dir, f"scaler_ws{window_size}.joblib")

            if os.path.exists(encoder_path) and os.path.exists(scaler_path):
                print(f"\n--- æ­£åœ¨åŠ è½½çª—å£å¤§å°ä¸º {window_size} å¤©çš„é¢„è®­ç»ƒæ¨¡å‹ ---")
                encoder = MaskedEncoder(
                    input_dim=input_dim,
                    hidden_dim=pretrain_config['encoder_hidden_dim'],
                    num_layers=pretrain_config['encoder_layers'],
                    final_embedding_dim=pretrain_config['final_embedding_dim']
                )
                encoder.load_state_dict(torch.load(encoder_path))
                encoder.eval() 
                scaler = joblib.load(scaler_path)
                print(f"   âœ… ä» {pretrained_models_dir} åŠ è½½äº†ç¼–ç å™¨å’Œç¼©æ”¾å™¨")
            else:
                print(f"\n--- æœªæ‰¾åˆ°é¢„è®­ç»ƒæ¨¡å‹ã€‚æ­£åœ¨ä¸ºçª—å£å¤§å° {window_size} å¤©è¿›è¡Œè®­ç»ƒ ---")
                encoder, scaler = self.pretrain_embedder(
                    df_for_pretraining,       
                    df_for_scaling,           
                    window_size=window_size,
                    config=pretrain_config
                )
                print(f"   -> è®­ç»ƒå®Œæˆã€‚æ­£åœ¨ä¸ºçª—å£ {window_size} ä¿å­˜æ¨¡å‹...")
                torch.save(encoder.state_dict(), encoder_path)
                joblib.dump(scaler, scaler_path)
                print(f"   âœ… å·²å°†ç¼–ç å™¨å’Œç¼©æ”¾å™¨ä¿å­˜è‡³ {pretrained_models_dir}")
                
            TLAFS_Algorithm.pretrained_encoders[window_size] = encoder
            TLAFS_Algorithm.embedder_scalers[window_size] = scaler

    def _log_baseline_performance(self):
        """Calculates and logs the initial baseline performance without any generated features."""
        from ..utils.evaluation import probe_feature_set
        print("\nEstablishing baseline performance...")
        # Baseline features are just the original non-target columns that are numeric
        initial_features = [col for col in self.base_df.columns if col not in ['date', self.target_col] and pd.api.types.is_numeric_dtype(self.base_df[col])]
        if not initial_features:
            print("No initial numeric features to establish a baseline. Setting baseline score to 0.")
            baseline_score = 0.0
            initial_features = []
        else:
            baseline_df = self.base_df[initial_features + [self.target_col]].copy()
            # The probe function needs to handle the case where the dataframe might be simple
            baseline_score, _ = probe_feature_set(baseline_df, self.target_col, features_to_probe=initial_features)
        
        self.best_score = baseline_score
        self.history.append({
            "iteration": 0,
            "plan": "Baseline",
            "feature_name": "Baseline",
            "performance": baseline_score,
            "adopted": True,
            "available_features": initial_features
        })
        print(f"Baseline RÂ² score: {baseline_score:.4f} with features: {initial_features}")

    def _format_history_for_prompt(self):
        """å°†ç®—æ³•å†å²æ ¼å¼åŒ–ä¸ºå¯¹LLMæœ‰æ„ä¹‰çš„ã€åŒ…å«è¾¹é™…è´¡çŒ®çš„å­—ç¬¦ä¸²ã€‚"""
        if not self.history:
            return "No history yet."

        prompt_str = "--- å†å²è®°å½•ä¸è¾¹é™…è´¡çŒ®åˆ†æ ---\n"
        prompt_str += "ä½ å°†æ ¹æ®ä»¥ä¸‹å†å²è®°å½•åˆ¶å®šæ–°çš„è®¡åˆ’ã€‚è¯·ä»”ç»†åˆ†ææ¯ä¸€æ­¥çš„å¾—å¤±ã€‚\n"

        # ç¬¬ä¸€ä¸ªæ¡ç›®æ˜¯åŸºçº¿
        baseline = self.history[0]
        prompt_str += f"ç¬¬0æ­¥ (åŸºçº¿): ä½¿ç”¨ç‰¹å¾ {self.summarize_feature_list(baseline['available_features'])}ï¼Œæˆ‘ä»¬å¾—åˆ°çš„åˆå§‹RÂ²ä¸º {baseline['performance']:.4f}ã€‚\n"

        # åç»­çš„è¿­ä»£
        for i in range(1, len(self.history)):
            current_step = self.history[i]
            prev_step = self.history[i-1]
            
            plan = current_step['plan']
            feature_name = current_step['feature_name']
            performance = current_step['performance']
            prev_performance = prev_step['performance']
            marginal_contribution = performance - prev_performance
            adopted = current_step['adopted']
            
            status = "âœ… (å·²é‡‡çº³)" if adopted else "âŒ (å·²æ‹’ç»)"
            analysis = ""
            if adopted:
                if marginal_contribution > 0.001:
                    analysis = f"æ€§èƒ½æ˜¾è‘—æå‡äº† {marginal_contribution:+.4f}ã€‚è¿™æ˜¯ä¸€ä¸ªæˆåŠŸçš„ç‰¹å¾ï¼Œè¯·è€ƒè™‘å…¶æ¨¡å¼ã€‚"
                elif marginal_contribution > -0.001:
                    analysis = f"æ€§èƒ½ç•¥å¾®æå‡ {marginal_contribution:+.4f}ã€‚è¿™æ˜¯ä¸€ä¸ªä¸­æ€§çš„ç‰¹å¾ã€‚"
                else:
                    analysis = f"æ€§èƒ½æ„å¤–ä¸‹é™äº† {marginal_contribution:+.4f}ã€‚è¿™æ˜¯ä¸€ä¸ª'æœ‰æ¯’'ç‰¹å¾ï¼Œè¯·é¿å…ç”Ÿæˆç±»ä¼¼çš„ç‰¹å¾ã€‚"
            else: # è¢«æ‹’ç»
                analysis = f"è®¡åˆ’è¢«æ‹’ç»ï¼Œå› ä¸ºå®ƒæ²¡æœ‰å¸¦æ¥è¶³å¤Ÿçš„æ€§èƒ½æå‡ (é˜ˆå€¼: {self.acceptance_threshold})ã€‚"

            prompt_str += (
                f"\nç¬¬{i}æ­¥: \n"
                f"  - è®¡åˆ’: {plan}\n"
                f"  - ç”Ÿæˆçš„ç‰¹å¾: '{feature_name}'\n"
                f"  - ç»“æœ: æ–°çš„RÂ²ä¸º {performance:.4f}ã€‚{status}\n"
                f"  - åˆ†æ: {analysis}\n"
            )
        
        # --- æ–°å¢: ç­–ç•¥åˆ†ææ¦‚è¦ ---
        successful_ops = defaultdict(int)
        failed_ops = defaultdict(int)
        # ä»ç¬¬1æ¬¡è¿­ä»£å¼€å§‹åˆ†æï¼ˆè·³è¿‡åŸºçº¿å’Œå¼ºåˆ¶å®ï¼‰
        analysis_start_index = 1
        # --- Bugä¿®å¤ï¼šå¢åŠ å¯¹historyé•¿åº¦çš„æ£€æŸ¥ ---
        if len(self.history) > 1 and self.history[1]['plan'].startswith("{'function': 'create_control_baseline_features'"):
            analysis_start_index = 2

        # --- Bugä¿®å¤ï¼šç¡®ä¿ç´¢å¼•èµ·ç‚¹ä¸è¶…è¿‡åˆ—è¡¨é•¿åº¦ ---
        if analysis_start_index < len(self.history):
            for step in self.history[analysis_start_index:]:
                plan_str = step['plan']
                match = re.search(r"'function':\s*'([^']*)'", plan_str)
                if match:
                    op_name = match.group(1)
                    if step['adopted']:
                        successful_ops[op_name] += 1
                    else:
                        failed_ops[op_name] += 1

        analysis_summary = "\n--- ç­–ç•¥åˆ†æ ---\n"
        if successful_ops or failed_ops:
            analysis_summary += "æ ¹æ®è¿‡å¾€è®°å½•ï¼Œä½ çš„ç­–ç•¥è¡¨ç°å¦‚ä¸‹ï¼š\n"
            if successful_ops:
                analysis_summary += f"  - âœ… æˆåŠŸçš„æ“ä½œç±»å‹: {json.dumps(dict(successful_ops))}\n"
            if failed_ops:
                analysis_summary += f"  - âŒ å¤±è´¥çš„æ“ä½œç±»å‹: {json.dumps(dict(failed_ops))}\n"
            analysis_summary += "è¯·æ ¹æ®ä»¥ä¸Šç»Ÿè®¡ï¼Œä¼˜å…ˆè€ƒè™‘æˆåŠŸçš„æ“ä½œç±»å‹ï¼Œé¿å…é‡å¤å¤±è´¥ã€‚\n"
        else:
            analysis_summary += "å°šæ— è¶³å¤Ÿå†å²è¿›è¡Œåˆ†æã€‚è¯·å¼€å§‹ä½ çš„æ¢ç´¢ã€‚\n"
        
        prompt_str += analysis_summary
        prompt_str += "\n--- End of History ---\n"
        return prompt_str


    def _generate_prompt(self, iteration_num, importance_report=None):
        """ä¸ºLLMç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„ã€ç»“æ„åŒ–çš„æç¤ºã€‚"""
        
        # 1. åˆå§‹ä¸Šä¸‹æ–‡ï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡è¿­ä»£æ—¶æ˜¾ç¤ºï¼‰
        initial_context = ""
        if iteration_num == 1:
            initial_context = "--- æ•°æ®é›†åˆ†ææŠ¥å‘Š ---\n"
            for key, value in self.dataset_analysis.items():
                initial_context += f"- {key}: {value}\n"
            initial_context += "è¯·åŸºäºä»¥ä¸ŠæŠ¥å‘Šå¼€å§‹ä½ çš„ç‰¹å¾å·¥ç¨‹è®¡åˆ’ã€‚\n"

        # 2. å†å²åˆ†æ
        history_summary = self._format_history_for_prompt()

        # 3. å½“å‰çŠ¶æ€ä¸ä»»åŠ¡
        current_features = self.history[-1]['available_features']
        summarized_features = self.summarize_feature_list(current_features)
        current_performance = self.history[-1]['performance']
        
        state_summary = (
            "--- å½“å‰çŠ¶æ€ä¸ä»»åŠ¡ ---\n"
            f"å½“å‰æ˜¯ç¬¬ {iteration_num}/{self.n_iterations} æ¬¡è¿­ä»£ã€‚\n"
            f"å½“å‰ç‰¹å¾é›† ({len(current_features)}ä¸ª): {summarized_features}\n"
            f"å½“å‰RÂ²åˆ†æ•°ä¸º: {current_performance:.4f}\n\n"
        )
        
        # 4. åŠ¨æ€ä»»åŠ¡æŒ‡ä»¤ï¼ˆå¸¸è§„ vs å¤ç›˜ï¼‰
        task_instruction = ""
        if importance_report is not None:
            useless_features = importance_report[importance_report['importance_mean'] <= 0].index.tolist()
            task_instruction = (
                "**ç‰¹æ®Šä»»åŠ¡ï¼šå¤ç›˜ä¸ä¼˜åŒ–**\n"
                "æˆ‘ä»¬è¿›è¡Œäº†ä¸€æ¬¡ç‰¹å¾é‡è¦æ€§åˆ†æï¼ŒæŠ¥å‘Šå¦‚ä¸‹ï¼š\n"
                f"{importance_report.to_string()}\n"
                f"åˆ†æè¡¨æ˜ï¼Œä»¥ä¸‹ç‰¹å¾å¯èƒ½æ˜¯æ— ç”¨æˆ–æœ‰å®³çš„: {useless_features}\n"
                "ä½ çš„ä»»åŠ¡æ˜¯ï¼šæå‡ºä¸€ä¸ª**åŒ…å« `delete_features` æ“ä½œ**çš„è®¡åˆ’æ¥æ¸…ç†è¿™äº›ç‰¹å¾ï¼Œå¹¶å¯ä»¥ç»“åˆå…¶ä»–æ“ä½œè¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚\n"
            )
        else:
            task_instruction = "ä½ çš„ä»»åŠ¡æ˜¯ï¼šåŸºäºå†å²å’Œå½“å‰çŠ¶æ€ï¼Œæå‡ºä¸€ä¸ªåŒ…å«**1-3ä¸ªæ“ä½œ**çš„ç‰¹å¾å·¥ç¨‹è®¡åˆ’æ¥æå‡æ€§èƒ½ã€‚\n"
        
        state_summary += task_instruction

        # 5. å‡½æ•°å®šä¹‰å’ŒæŒ‡ä»¤
        instructions = """
--- å¯ç”¨å‡½æ•°ä¸æŒ‡ä»¤ ---
ä½ åªèƒ½ä»ä»¥ä¸‹å‡½æ•°ä¸­é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªæ¥è°ƒç”¨ï¼š

**å®åŠŸèƒ½:**
1. `create_control_baseline_features(df, col)`: ä¸€æ¬¡æ€§åˆ›å»ºä¸€å¥—è¢«è¯æ˜æœ‰æ•ˆçš„åŸºç¡€ç‰¹å¾ã€‚

**åŸºç¡€åŠŸèƒ½:**
2. `create_lag_features(df, col, lags)`: åˆ›å»ºæ»åç‰¹å¾ã€‚
3. `create_rolling_features(df, col, windows, aggs)`: åˆ›å»ºæ»šåŠ¨ç‰¹å¾ã€‚
4. `create_fourier_features(df, col, order)`: åˆ›å»ºå‚…é‡Œå¶ç‰¹å¾ (æ³¨æ„: `col` å‚æ•°å¿…é¡»æ˜¯ 'date')ã€‚
5. `create_interaction_features(df, col1, col2)`: åˆ›å»ºäº¤äº’ç‰¹å¾ã€‚
6. `create_embedding_features(df, col, window_size)`: åˆ›å»ºåµŒå…¥ç‰¹å¾ (å¯ç”¨size: 90, 365, 730)ã€‚

**ä¼˜åŒ–åŠŸèƒ½:**
7. `delete_features(df, cols)`: åˆ é™¤ä¸€ä¸ªæˆ–å¤šä¸ªç‰¹å¾ã€‚

**è¾“å‡ºæ ¼å¼:**
ä½ çš„å›ç­”å¿…é¡»æ˜¯ä¸€ä¸ªä¸å«ä»»ä½•è§£é‡Šçš„ã€ä¸¥æ ¼çš„JSON**åˆ—è¡¨**ï¼Œå³ä½¿åªæœ‰ä¸€ä¸ªæ“ä½œä¹Ÿè¦åœ¨åˆ—è¡¨ä¸­ï¼š
`[{"function": "func_name", "args": {...}}, ...]`

**é‡è¦è§„åˆ™:**
- è®¡åˆ’å¯ä»¥åŒ…å«1åˆ°3ä¸ªæ“ä½œã€‚
- åªèƒ½ä½¿ç”¨å½“å‰ç‰¹å¾é›†ä¸­çš„åˆ—ã€‚
- **è¿›è¡Œå¤ç›˜ä»»åŠ¡æ—¶ï¼Œå¿…é¡»åŒ…å« `delete_features` æ“ä½œã€‚**
- **æ•°æ®æ³„éœ²è­¦å‘Šï¼š`create_interaction_features` ç»ä¸èƒ½ç›´æ¥ä½¿ç”¨ç›®æ ‡åˆ— ('{self.target_col}')ã€‚å¦‚æœä½ æƒ³ä½¿ç”¨ç›®æ ‡å€¼çš„ä¿¡æ¯ï¼Œå¿…é¡»å…ˆåˆ›å»ºå®ƒçš„æ»åæˆ–æ»šåŠ¨ç‰¹å¾ (ä¾‹å¦‚ `temp_lag_1`)ï¼Œç„¶åä¸é‚£ä¸ªæ–°ç”Ÿæˆçš„ã€æ— æ³„æ¼çš„ç‰¹å¾è¿›è¡Œäº¤äº’ã€‚**
- **ç­–ç•¥æŒ‡å¯¼ï¼šé¿å…é‡å¤æäº¤è¿‘æœŸå·²è¢«æ‹’ç»çš„è®¡åˆ’æˆ–ç‰¹å¾ã€‚è¯·å°è¯•æ›´å¤šæ ·åŒ–çš„ç­–ç•¥ã€‚**
- **`create_control_baseline_features` åªèƒ½åœ¨ç¬¬ä¸€æ­¥ä½¿ç”¨ï¼Œåç»­è¿­ä»£ä¸åº”å†è°ƒç”¨ã€‚**
"""
        
        return initial_context + history_summary + state_summary + instructions

    def get_plan_from_llm(self, iteration_num, importance_report=None):
        """ä½¿ç”¨æ–°çš„ç”Ÿæˆå™¨è·å–LLMçš„è®¡åˆ’ã€‚"""
        prompt = self._generate_prompt(iteration_num, importance_report)
        
        print("\n" + "="*40)
        task_type = "å¤ç›˜ä¸ä¼˜åŒ–" if importance_report is not None else "å¸¸è§„æ¢ç´¢"
        print(f"è¿­ä»£ {iteration_num} ({task_type}): æ­£åœ¨å‘LLMè¯·æ±‚è®¡åˆ’...")

        try:
            response = TLAFS_Algorithm.gemini_model.generate_content(prompt)
            # LLMç°åœ¨åº”è¿”å›ä¸€ä¸ªåˆ—è¡¨
            plan_json = json.loads(response.text)
            if not isinstance(plan_json, list):
                plan_json = [plan_json] # å…¼å®¹å•ä¸ªæ“ä½œçš„æ—§æ ¼å¼
            print(f"âœ… ä»LLMæ¥æ”¶åˆ°è®¡åˆ’: {plan_json}")
            return plan_json
        except Exception as e:
            print(f"âŒ è§£æLLMå“åº”æ—¶å‡ºé”™: {e}")
            print("å°†ä½¿ç”¨ä¸€ä¸ªå¤‡ç”¨è®¡åˆ’ã€‚")
            fallback_col = random.choice(self.history[-1]['available_features'])
            return [{"function": "create_lag_features", "args": {"col": fallback_col, "lags": [random.randint(1, 14)]}}]
    
    def run(self, execute_plan_func, probe_func):
        """
        è¿è¡ŒT-LAFSç®—æ³•çš„ä¸»å¾ªç¯ã€‚
        """
        print("\n" + "="*80)
        print("ğŸš€ å¼€å§‹T-LAFSç‰¹å¾æœç´¢å¾ªç¯...")
        print("="*80)

        # Bugä¿®å¤: ç¡®ä¿best_dfå§‹ç»ˆåŒ…å«æ‰€æœ‰å¿…è¦çš„åˆ—ï¼Œç‰¹åˆ«æ˜¯'date'
        self.best_df = self.base_df.copy()

        # --- å¼ºåˆ¶æ‰§è¡Œ 'control' åŸºçº¿ç‰¹å¾ä½œä¸ºç¬¬0æ­¥ ---
        print("\n" + "="*40)
        print("ğŸš€ æ­¥éª¤ 0: å¼ºåˆ¶æ‰§è¡Œ'control.py'ç‰¹å¾å·¥ç¨‹å®")
        print("="*40)
        
        control_plan = {"function": "create_control_baseline_features", "args": {"col": self.target_col}}
        # ä½¿ç”¨self.best_dfï¼ˆå³self.base_dfçš„å‰¯æœ¬ï¼‰æ¥æ‰§è¡Œè®¡åˆ’
        temp_df, new_feature_name = execute_plan_func(self.best_df.copy(), control_plan)
        
        if temp_df is not None and new_feature_name is not None:
            features_to_probe = [c for c in temp_df.columns if c not in ['date', self.target_col]]
            new_score, _ = probe_func(temp_df, self.target_col, features_to_probe)
            
            improvement = new_score - self.best_score
            print(f"  - 'control'å®ç”Ÿæˆç‰¹å¾é›†ï¼Œæ¢æµ‹ RÂ²: {new_score:.4f} (æå‡: {improvement:+.4f})")
            
            # è¿™ä¸ªå¼ºåˆ¶æ­¥éª¤æ€»æ˜¯è¢«é‡‡çº³ï¼Œå½¢æˆæ–°çš„ã€æ›´å¼ºçš„åŸºçº¿
            self.best_score = new_score
            self.best_df = temp_df
            
            # è®°å½•è¿™ä¸ªå¼ºåˆ¶æ­¥éª¤
            self.history.append({
                "iteration": "Baseline+",
                "plan": str(control_plan),
                "feature_name": new_feature_name,
                "performance": new_score,
                "adopted": True,
                "available_features": features_to_probe
            })
        else:
            print("âš ï¸ 'control'å®ç‰¹å¾ç”Ÿæˆå¤±è´¥ã€‚ç»§ç»­ä½¿ç”¨åŸå§‹åŸºçº¿ã€‚")


        # --- è¿­ä»£æ¢ç´¢å¾ªç¯ ---
        for i in range(1, self.n_iterations + 1):
            
            # --- æ–°å¢ï¼šå‘¨æœŸæ€§å¤ç›˜é€»è¾‘ ---
            if i > 1 and i % self.review_interval == 0:
                print("\n" + "="*50)
                print(f"ğŸ”¬ è§¦å‘å‘¨æœŸæ€§å¤ç›˜ (è¿­ä»£ {i}) ğŸ”¬")
                print("="*50)
                
                # 1. è¿è¡Œæ’åˆ—é‡è¦æ€§åˆ†æ
                current_features = self.history[-1]['available_features']
                X_val = self.best_df[current_features]
                y_val = self.best_df[self.target_col]
                
                # åˆ›å»ºä¸€ä¸ªä¸´æ—¶æ¨¡å‹ç”¨äºåˆ†æ
                lgbm = lgb.LGBMRegressor(random_state=42, verbosity=-1)
                lgbm.fit(X_val, y_val) # åœ¨å½“å‰æ‰€æœ‰å¯ç”¨æ•°æ®ä¸Šè®­ç»ƒ
                
                importance_df = calculate_permutation_importance(
                    model=lgbm, X_val=X_val, y_val=y_val, metric_func=r2_score
                )
                
                # 2. è·å–å¸¦æœ‰å¤ç›˜ä¸Šä¸‹æ–‡çš„è®¡åˆ’
                plan = self.get_plan_from_llm(i, importance_report=importance_df)
            else:
                # å¸¸è§„è¿­ä»£
                plan = self.get_plan_from_llm(i)

            # 2. æ‰§è¡Œè®¡åˆ’ (ç°åœ¨planæ˜¯ä¸€ä¸ªåˆ—è¡¨)
            temp_df, new_feature_name = execute_plan_func(self.best_df.copy(), plan)

            if temp_df is None or new_feature_name is None:
                print("âš ï¸ æ‰§è¡Œè®¡åˆ’å¤±è´¥æˆ–æœªç”Ÿæˆæ–°ç‰¹å¾ï¼Œè·³è¿‡æ­¤è¿­ä»£ã€‚")
                # å¯¹äºå¤±è´¥çš„è®¡åˆ’ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥è®°å½•ä¸‹æ¥
                self.history.append({
                    "iteration": i, "plan": str(plan), "feature_name": "Execution Failed",
                    "performance": self.best_score, "adopted": False,
                    "available_features": list(self.best_df.columns)
                })
                continue
            
            # 3. æ¢æµ‹æ–°ç‰¹å¾é›†çš„æ€§èƒ½
            features_to_probe = [c for c in temp_df.columns if c not in ['date', self.target_col]]
            new_score, _ = probe_func(temp_df, self.target_col, features_to_probe)
            
            # 4. å†³å®šæ˜¯å¦é‡‡çº³æ–°ç‰¹å¾
            improvement = new_score - self.best_score
            adopted = improvement > self.acceptance_threshold
            
            print(f"  - æ–°ç‰¹å¾ '{new_feature_name}' çš„æ¢æµ‹RÂ²: {new_score:.4f} (æå‡: {improvement:+.4f})")

            if adopted:
                print(f"  âœ… å·²é‡‡çº³: æ€§èƒ½æå‡è¶…è¿‡é˜ˆå€¼ {self.acceptance_threshold}")
                self.best_score = new_score
                self.best_df = temp_df
                self.best_plan.append(plan)
            else:
                print(f"  âŒ å·²æ‹’ç»: æ€§èƒ½æå‡ä¸è¶³ã€‚")

            # 5. è®°å½•å†å²
            features_for_history = []
            if adopted:
                features_for_history = [c for c in temp_df.columns if c not in ['date', self.target_col]]
            else:
                # å¦‚æœæœªé‡‡çº³ï¼Œåˆ™å¯ç”¨ç‰¹å¾é›†ä¸ä¸Šä¸€æ­¥ç›¸åŒ
                features_for_history = self.history[-1]['available_features']

            self.history.append({
                "iteration": i,
                "plan": str(plan),
                "feature_name": new_feature_name,
                "performance": new_score, # è®°å½•çš„æ˜¯æœ¬æ¬¡å°è¯•çš„åˆ†æ•°
                "adopted": adopted,
                "available_features": features_for_history
            })

        print("\n" + "="*80)
        print("ğŸ† T-LAFSç‰¹å¾æœç´¢å¾ªç¯å®Œæˆã€‚")
        print(f"ğŸ† æ‰¾åˆ°çš„æœ€ä½³RÂ²åˆ†æ•°: {self.best_score:.4f}")
        print(f"ğŸ“‹ æœ€ç»ˆé‡‡çº³çš„è®¡åˆ’: {self.best_plan}")
        print("="*80)
        
        final_df = self.best_df.copy()
        final_plan = self.best_plan
        final_score = self.best_score

        return final_df, final_plan, final_score

    def _initial_setup(self):
        """æ‰§è¡Œæ‰€æœ‰ä¸€æ¬¡æ€§çš„åˆå§‹åŒ–æ­¥éª¤ã€‚"""
        # 1. è‡ªåŠ¨åŒ–æ•°æ®é›†åˆ†æ
        self.dataset_analysis = analyze_dataset_characteristics(self.base_df, self.target_col)
        
        # 2. é¢„è®­ç»ƒæ¨¡å‹
        self._initialize_and_pretrain_models()
        
        # 3. è®°å½•åŸºçº¿æ€§èƒ½
        self._log_baseline_performance() 